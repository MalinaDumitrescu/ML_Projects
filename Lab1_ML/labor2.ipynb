{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 1 — imports & options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.future.infer_string = True"
   ],
   "id": "b1091d82b0c328d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Returns most frequent value in a Series (used to fill categorical modes).\n",
    "def simple_mode(s: pd.Series):\n",
    "    m = s.mode(dropna=True)\n",
    "    return m.iloc[0] if len(m) else np.nan\n",
    "\n",
    "# Clips negative numeric values (area/count columns) to zero.\n",
    "def enforce_nonnegative(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clip logical non-negative numerics at 0 (defensive net).\"\"\"\n",
    "    nonneg = [\n",
    "        'Lot Area','Lot Frontage','Gr Liv Area',\n",
    "        'BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF',\n",
    "        'Garage Area','Garage Cars','1st Flr SF','2nd Flr SF','Low Qual Fin SF',\n",
    "        'Wood Deck SF','Open Porch SF','Enclosed Porch','3Ssn Porch','Screen Porch',\n",
    "        'Pool Area','SalePrice'\n",
    "    ]\n",
    "    for c in nonneg:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].clip(lower=0)\n",
    "    return df\n",
    "\n",
    "def normalize_categoricals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Trim/standardize string categories (avoids hidden ‘NaN ’, ‘ y ’, etc.).\"\"\"\n",
    "    obj_cols = df.select_dtypes(include='object').columns\n",
    "    for c in obj_cols:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "        df.loc[df[c].isin(['', 'nan', 'None', 'NaT']), c] = np.nan\n",
    "    # Central Air should be Y/N\n",
    "    if 'Central Air' in df.columns:\n",
    "        df['Central Air'] = df['Central Air'].replace({'Yes': 'Y', 'No': 'N', 'y': 'Y', 'n': 'N'})\n",
    "    return df\n",
    "\n",
    "def apply_absence_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    na_none_map = {\n",
    "        'Alley': 'NoAlley',\n",
    "        'Bsmt Qual': 'NoBasement','Bsmt Cond': 'NoBasement','Bsmt Exposure': 'NoBasement',\n",
    "        'BsmtFin Type 1': 'NoBasement','BsmtFin Type 2': 'NoBasement',\n",
    "        'Fireplace Qu': 'NoFireplace',\n",
    "        'Garage Type': 'NoGarage','Garage Finish': 'NoGarage','Garage Qual': 'NoGarage','Garage Cond': 'NoGarage',\n",
    "        'Pool QC': 'NoPool','Fence': 'NoFence','Misc Feature': 'NoFeature'\n",
    "    }\n",
    "    for col, val in na_none_map.items():\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace('NA', val).fillna(val)\n",
    "    return df\n",
    "\n",
    "def fix_basement_consistency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    parts = ['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF']; total = 'Total Bsmt SF'\n",
    "    has_bsmt_area = (df[parts].fillna(0).sum(axis=1) > 0)\n",
    "    bad_expo = has_bsmt_area & (df['Bsmt Exposure'] == 'NoBasement')\n",
    "    df['Fix_BsmtExposure'] = 0\n",
    "    df.loc[bad_expo, 'Bsmt Exposure'] = 'No'\n",
    "    df.loc[bad_expo, 'Fix_BsmtExposure'] = 1\n",
    "\n",
    "    sum_parts = df[parts].fillna(0).sum(axis=1)\n",
    "    all_parts_na = df[parts].isna().all(axis=1)\n",
    "    total_na = df[total].isna()\n",
    "\n",
    "    mask_true_mismatch = (~all_parts_na) & (~total_na) & (df[total] != sum_parts)\n",
    "    mask_total_missing = (~all_parts_na) & total_na\n",
    "    df.loc[mask_true_mismatch, total] = sum_parts[mask_true_mismatch]\n",
    "    df.loc[mask_total_missing, total] = sum_parts[mask_total_missing]\n",
    "\n",
    "    mask_parts_missing = all_parts_na & (~total_na)\n",
    "    for c in parts:\n",
    "        df.loc[mask_parts_missing, c] = df.loc[mask_parts_missing, c].fillna(0)\n",
    "\n",
    "    mask_all_missing = all_parts_na & total_na & (df['Bsmt Qual'] == 'NoBasement')\n",
    "    for c in parts + [total]:\n",
    "        df.loc[mask_all_missing, c] = 0\n",
    "    return df\n",
    "\n",
    "def consolidate_garage_absence(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"If no garage (type/area/cars imply absence), zero numerics + set labels to NoGarage.\"\"\"\n",
    "    g_zero = (df.get('Garage Cars', 0).fillna(0) == 0) & (df.get('Garage Area', 0).fillna(0) == 0)\n",
    "    if 'Garage Type' in df.columns:\n",
    "        g_abs = (df['Garage Type'] == 'NoGarage') | g_zero\n",
    "        for c in ['Garage Finish','Garage Qual','Garage Cond','Garage Type']:\n",
    "            if c in df.columns:\n",
    "                df.loc[g_abs, c] = 'NoGarage'\n",
    "        for c in ['Garage Yr Blt','Garage Area','Garage Cars']:\n",
    "            if c in df.columns:\n",
    "                df.loc[g_abs, c] = 0\n",
    "    return df\n",
    "\n",
    "def apply_time_filters(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[(df['Yr Sold'] >= df['Year Built']) & (df['Yr Sold'] >= df['Year Remod/Add'])].copy()\n",
    "    df = df[df['Year Remod/Add'] >= df['Year Built']].copy()\n",
    "    mask_gyear_ok = (~df['Garage Yr Blt'].notna()) | (\n",
    "        (df['Garage Yr Blt'] >= 1880) & (df['Garage Yr Blt'] <= (df['Yr Sold'] + 1))\n",
    "    )\n",
    "    return df[mask_gyear_ok].copy()\n",
    "\n",
    "def add_binary_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['HasPool']   = (df['Pool Area'] > 0).astype(int)\n",
    "    df['HasFire']   = (df['Fireplaces'] > 0).astype(int)\n",
    "    df['HasAC']     = (df['Central Air'] == 'Y').astype(int)\n",
    "    df['HasFence']  = (df['Fence'] != 'NoFence').astype(int)\n",
    "    df['HasGarage'] = (df['Garage Cars'].fillna(0) > 0).astype(int)\n",
    "    df['AmenitiesCount'] = df[['HasPool','HasFire','HasAC','HasFence','HasGarage']].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def drop_low_signal_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    to_drop = ['Utilities','Street','Condition 2','Roof Matl','Heating','Pool QC','Misc Feature','Garage Cond']\n",
    "    keep = [c for c in to_drop if c in df.columns]\n",
    "    return df.drop(columns=keep).copy()\n",
    "\n",
    "def ordinal_encode_inplace(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ord_orders = {\n",
    "        'Exter Qual':['Po','Fa','TA','Gd','Ex'],'Exter Cond':['Po','Fa','TA','Gd','Ex'],\n",
    "        'Bsmt Qual':['NoBasement','Po','Fa','TA','Gd','Ex'],'Bsmt Cond':['NoBasement','Po','Fa','TA','Gd','Ex'],\n",
    "        'Bsmt Exposure':['NoBasement','No','Mn','Av','Gd'],\n",
    "        'BsmtFin Type 1':['NoBasement','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\n",
    "        'BsmtFin Type 2':['NoBasement','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\n",
    "        'Heating QC':['Po','Fa','TA','Gd','Ex'],'Electrical':['FuseP','FuseF','Mix','FuseA','SBrkr'],\n",
    "        'Kitchen Qual':['Po','Fa','TA','Gd','Ex'],'Fireplace Qu':['NoFireplace','Po','Fa','TA','Gd','Ex'],\n",
    "        'Garage Finish':['NoGarage','Unf','RFn','Fin'],'Garage Qual':['NoGarage','Po','Fa','TA','Gd','Ex'],\n",
    "        'Paved Drive':['N','P','Y'],'Lot Shape':['IR3','IR2','IR1','Reg'],'Land Slope':['Sev','Mod','Gtl'],\n",
    "    }\n",
    "    for col, order in ord_orders.items():\n",
    "        if col in df.columns:\n",
    "            cat = pd.Categorical(df[col], categories=order, ordered=True)\n",
    "            s = pd.Series(cat.codes, index=df.index).astype('float64')\n",
    "            s[s == -1] = np.nan\n",
    "            df[col] = s\n",
    "    return df\n",
    "\n",
    "def bucket_rare(df: pd.DataFrame, cols: list, min_count: int = 5) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            s = df[c].astype(str)  # TODO check--> edge case\n",
    "            vc = df[c].value_counts(dropna=False)\n",
    "            rare = set(vc[vc < min_count].index)\n",
    "            df[c] = df[c].where(~df[c].isin(rare), \"__Other__\")\n",
    "    return df\n"
   ],
   "id": "7d036c0638ba3865",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_train_stats(df_tr: pd.DataFrame):\n",
    "    stats = {}\n",
    "    if 'Lot Frontage' in df_tr.columns and 'Neighborhood' in df_tr.columns:\n",
    "        stats['lf_med_nb']   = df_tr.groupby('Neighborhood')['Lot Frontage'].median()\n",
    "        stats['lf_med_glob'] = df_tr['Lot Frontage'].median()\n",
    "    else:\n",
    "        stats['lf_med_nb'] = pd.Series(dtype='float64'); stats['lf_med_glob'] = np.nan\n",
    "\n",
    "    label_cols_all = ['Garage Finish','Garage Qual','Garage Cond']\n",
    "    label_cols = [c for c in label_cols_all if c in df_tr.columns]\n",
    "    g_has_tr = (\n",
    "        (df_tr.get('Garage Type', 'NoGarage') != 'NoGarage') |\n",
    "        (df_tr.get('Garage Area', pd.Series(0, index=df_tr.index)).fillna(0) > 0) |\n",
    "        (df_tr.get('Garage Cars', pd.Series(0, index=df_tr.index)).fillna(0) > 0)\n",
    "    )\n",
    "    if 'Garage Type' in df_tr.columns and any(label_cols):\n",
    "        try:\n",
    "            stats['g_modes_by_type'] = df_tr[g_has_tr].groupby('Garage Type')[label_cols].agg(simple_mode)\n",
    "        except Exception:\n",
    "            stats['g_modes_by_type'] = pd.DataFrame()\n",
    "    else:\n",
    "        stats['g_modes_by_type'] = pd.DataFrame()\n",
    "\n",
    "    stats['g_med_area_by_type'] = (df_tr[g_has_tr].groupby('Garage Type')['Garage Area'].median()\n",
    "                                   if {'Garage Type','Garage Area'} <= set(df_tr.columns) else pd.Series(dtype='float64'))\n",
    "    stats['g_med_cars_by_type'] = (df_tr[g_has_tr].groupby('Garage Type')['Garage Cars'].median()\n",
    "                                   if {'Garage Type','Garage Cars'} <= set(df_tr.columns) else pd.Series(dtype='float64'))\n",
    "\n",
    "    if {'Mas Vnr Area','Mas Vnr Type'} <= set(df_tr.columns):\n",
    "        ref = df_tr[(df_tr['Mas Vnr Area'].fillna(0) > 0) & df_tr['Mas Vnr Type'].notna() & (df_tr['Mas Vnr Type'] != 'None')]\n",
    "        stats['mvt_nb_mode'] = (ref.groupby('Neighborhood')['Mas Vnr Type'].agg(simple_mode)\n",
    "                                if 'Neighborhood' in df_tr.columns else pd.Series(dtype='object'))\n",
    "        gmode = df_tr['Mas Vnr Type'].dropna().mode()\n",
    "        stats['mvt_global_mode'] = gmode.iloc[0] if len(gmode) else 'BrkFace'\n",
    "    else:\n",
    "        stats['mvt_nb_mode'] = pd.Series(dtype='object'); stats['mvt_global_mode'] = 'BrkFace'\n",
    "\n",
    "    num_cols = [c for c in df_tr.select_dtypes(include=[np.number]).columns if c != 'SalePrice']\n",
    "    stats['num_medians'] = df_tr[num_cols].median(numeric_only=True)\n",
    "    return stats\n",
    "\n",
    "def apply_train_stats(df_block: pd.DataFrame, stats: dict) -> pd.DataFrame:\n",
    "    if {'Lot Frontage','Neighborhood'} <= set(df_block.columns) and not pd.isna(stats.get('lf_med_glob', np.nan)):\n",
    "        df_block['Lot Frontage'] = df_block['Lot Frontage'].fillna(df_block['Neighborhood'].map(stats['lf_med_nb'])).fillna(stats['lf_med_glob'])\n",
    "\n",
    "    g_has = (\n",
    "        (df_block.get('Garage Type', 'NoGarage') != 'NoGarage') |\n",
    "        (df_block.get('Garage Area', pd.Series(0, index=df_block.index)).fillna(0) > 0) |\n",
    "        (df_block.get('Garage Cars', pd.Series(0, index=df_block.index)).fillna(0) > 0)\n",
    "    )\n",
    "    if isinstance(stats.get('g_modes_by_type'), pd.DataFrame) and not stats['g_modes_by_type'].empty and 'Garage Type' in df_block.columns:\n",
    "        need_fix = g_has & (\n",
    "            (df_block.get('Garage Finish', pd.Series(np.nan, index=df_block.index)).isna()) |\n",
    "            (df_block.get('Garage Qual',   pd.Series(np.nan, index=df_block.index)).isna()) |\n",
    "            (df_block.get('Garage Cond',   pd.Series(np.nan, index=df_block.index)).isna()) |\n",
    "            (df_block.get('Garage Finish', pd.Series('NoGarage', index=df_block.index)) == 'NoGarage') |\n",
    "            (df_block.get('Garage Qual',   pd.Series('NoGarage', index=df_block.index)) == 'NoGarage') |\n",
    "            (df_block.get('Garage Cond',   pd.Series('NoGarage', index=df_block.index)) == 'NoGarage')\n",
    "        )\n",
    "        for c in ['Garage Finish','Garage Qual','Garage Cond']:\n",
    "            if c in df_block.columns and c in stats['g_modes_by_type'].columns:\n",
    "                fill_vals = df_block.loc[need_fix, 'Garage Type'].map(stats['g_modes_by_type'][c])\n",
    "                df_block.loc[need_fix, c] = df_block.loc[need_fix, c].fillna(fill_vals)\n",
    "\n",
    "    if {'Garage Area','Garage Type'} <= set(df_block.columns) and not stats.get('g_med_area_by_type', pd.Series()).empty:\n",
    "        m_area_na = g_has & df_block['Garage Area'].isna()\n",
    "        df_block.loc[m_area_na, 'Garage Area'] = df_block.loc[m_area_na, 'Garage Type'].map(stats['g_med_area_by_type'])\n",
    "    if {'Garage Cars','Garage Type'} <= set(df_block.columns) and not stats.get('g_med_cars_by_type', pd.Series()).empty:\n",
    "        m_cars_na = g_has & df_block['Garage Cars'].isna()\n",
    "        df_block.loc[m_cars_na, 'Garage Cars'] = df_block.loc[m_cars_na, 'Garage Type'].map(stats['g_med_cars_by_type'])\n",
    "\n",
    "    if {'Mas Vnr Area','Mas Vnr Type'} <= set(df_block.columns):\n",
    "        area = df_block['Mas Vnr Area']; typ = df_block['Mas Vnr Type']\n",
    "        m_area0 = area.fillna(0) == 0; m_area_pos = area.fillna(0) > 0\n",
    "        m_type_none = typ == 'None'; m_type_na = typ.isna()\n",
    "        df_block.loc[m_type_na & m_area0, 'Mas Vnr Type'] = 'None'\n",
    "        df_block.loc[(~m_type_none & ~m_type_na) & m_area0, 'Mas Vnr Type'] = 'None'\n",
    "        mask_pos_missing = m_area_pos & (m_type_none | m_type_na)\n",
    "        nb_mode = stats.get('mvt_nb_mode', pd.Series(dtype='object')); global_mode = stats.get('mvt_global_mode', 'BrkFace')\n",
    "        if not nb_mode.empty and 'Neighborhood' in df_block.columns:\n",
    "            nb_fill = df_block.loc[mask_pos_missing, 'Neighborhood'].map(nb_mode).fillna(global_mode)\n",
    "        else:\n",
    "            nb_fill = pd.Series(global_mode, index=df_block.index).loc[mask_pos_missing]\n",
    "        df_block.loc[mask_pos_missing, 'Mas Vnr Type'] = nb_fill\n",
    "    return df_block\n",
    "\n",
    "def fill_not_present_numerics(df_block: pd.DataFrame) -> pd.DataFrame:\n",
    "    exist_num = ['Garage Yr Blt','Garage Area','Garage Cars',\n",
    "                 'BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF',\n",
    "                 'Bsmt Full Bath','Bsmt Half Bath','Pool Area','Mas Vnr Area']\n",
    "    for c in exist_num:\n",
    "        if c in df_block.columns:\n",
    "            df_block[f'{c}_was_missing'] = df_block[c].isna().astype(int)\n",
    "            df_block[c] = df_block[c].fillna(0)\n",
    "    return df_block\n",
    "\n",
    "def fill_remaining_numerics_with_train_median(df_block: pd.DataFrame, num_medians: pd.Series) -> pd.DataFrame:\n",
    "    for c in df_block.select_dtypes(include=[np.number]).columns:\n",
    "        if df_block[c].isna().any():\n",
    "            df_block[c] = df_block[c].fillna(num_medians.get(c, df_block[c].median()))\n",
    "    return df_block"
   ],
   "id": "16c4032b270055a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_sanity_report(df_raw, df_train_clean, df_test_clean, meta, make_plots=True):\n",
    "    df_clean_all = pd.concat([df_train_clean, df_test_clean], ignore_index=True)\n",
    "    n_raw = meta.get('n_raw', len(df_raw)); n_after_time = meta.get('n_after_time', len(df_clean_all))\n",
    "    dropped_time = n_raw - n_after_time; pct_dropped = (dropped_time / n_raw) * 100 if n_raw else 0\n",
    "    print(\"=== Sanity report ===\")\n",
    "    print(f\"- Rows initiale: {n_raw}\")\n",
    "    print(f\"- După filtre temporale: {n_after_time}  (drop: {dropped_time} | {pct_dropped:.2f}%)\")\n",
    "    n_fix_bsmt = meta.get('n_fix_bsmt_exposure', int(df_clean_all.get('Fix_BsmtExposure', pd.Series(0)).sum()))\n",
    "    print(f\"- Corecții Bsmt Exposure (NoBasement -> No când există arii): {n_fix_bsmt}\")\n",
    "\n",
    "    parts = ['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF']; total = 'Total Bsmt SF'\n",
    "    if all(c in df_clean_all.columns for c in parts+[total]):\n",
    "        mismatch = (df_clean_all[total] != df_clean_all[parts].fillna(0).sum(axis=1)).sum()\n",
    "        print(f\"- Identități subsol (Total == sum(parts)) → mismatches: {mismatch}\")\n",
    "    else:\n",
    "        print(\"- Identități subsol: coloane lipsă, skip.\")\n",
    "\n",
    "    na_raw = df_raw.isna().sum().sort_values(ascending=False)\n",
    "    na_clean = df_clean_all.isna().sum().sort_values(ascending=False)\n",
    "    print(\"\\nTop 10 coloane cu NaN (înainte):\"); print(na_raw.head(10))\n",
    "    print(\"\\nTop 10 coloane cu NaN (după curățare):\"); print(na_clean.head(10))\n",
    "    print(f\"\\nShapes: train={df_train_clean.shape}, test={df_test_clean.shape}\")\n",
    "    if 'SalePrice' in df_raw.columns:\n",
    "        sp_raw = df_raw['SalePrice'].dropna(); sp_clean = df_clean_all['SalePrice'].dropna()\n",
    "        print(f\"SalePrice (raw):   n={sp_raw.size}, min={sp_raw.min():,.0f}, median={sp_raw.median():,.0f}, max={sp_raw.max():,.0f}\")\n",
    "        print(f\"SalePrice (clean): n={sp_clean.size}, min={sp_clean.min():,.0f}, median={sp_clean.median():,.0f}, max={sp_clean.max():,.0f}\")\n",
    "\n",
    "    if make_plots:\n",
    "        try: plot_sanity(df_raw, df_clean_all)\n",
    "        except Exception as e: print(f\"(plot warning) {e}\")\n",
    "\n",
    "def plot_sanity(df_raw, df_clean):\n",
    "    if 'SalePrice' in df_raw.columns and 'SalePrice' in df_clean.columns:\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.hist(df_raw['SalePrice'].dropna(), bins=50, alpha=0.35, label='raw')\n",
    "        plt.hist(df_clean['SalePrice'].dropna(), bins=50, alpha=0.6, label='clean')\n",
    "        plt.title(\"SalePrice: raw vs clean (hist)\"); plt.xlabel(\"SalePrice\"); plt.ylabel(\"count\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    if all(c in df_clean.columns for c in ['Gr Liv Area','SalePrice']):\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.scatter(df_clean['Gr Liv Area'], df_clean['SalePrice'], s=8, alpha=0.5)\n",
    "        plt.title(\"SalePrice vs Gr Liv Area (clean)\"); plt.xlabel(\"Gr Liv Area\"); plt.ylabel(\"SalePrice\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "def validate_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a small table of issues (row_idx, column, rule, value) without mutating df.\"\"\"\n",
    "    issues = []\n",
    "    def report(mask, col, rule):\n",
    "        idx = df.index[mask]\n",
    "        for i in idx:\n",
    "            issues.append((int(i), col, rule, df.at[i, col] if col in df.columns else None))\n",
    "\n",
    "    if {'Mo Sold','Yr Sold'} <= set(df.columns):\n",
    "        report(~df['Mo Sold'].between(1,12), 'Mo Sold', 'month_out_of_range')\n",
    "        report(~df['Yr Sold'].between(1800, 2100), 'Yr Sold', 'year_out_of_range')\n",
    "\n",
    "    if {'Overall Qual','Overall Cond'} <= set(df.columns):\n",
    "        report(~df['Overall Qual'].between(1,10), 'Overall Qual', 'qual_out_of_range')\n",
    "        report(~df['Overall Cond'].between(1,10), 'Overall Cond', 'cond_out_of_range')\n",
    "\n",
    "    if {'Year Built','Year Remod/Add'} <= set(df.columns):\n",
    "        report(df['Year Remod/Add'] < df['Year Built'], 'Year Remod/Add', 'remod_before_built')\n",
    "\n",
    "    if {'Garage Yr Blt','Yr Sold'} <= set(df.columns):\n",
    "        gy = df['Garage Yr Blt']; ys = df['Yr Sold']\n",
    "        report(gy.notna() & (gy < 1880), 'Garage Yr Blt', 'garage_too_old')\n",
    "        report(gy.notna() & (gy > ys + 1), 'Garage Yr Blt', 'garage_after_sale+1')\n",
    "\n",
    "    pos_when_present = ['Gr Liv Area','1st Flr SF','SalePrice']\n",
    "    for c in pos_when_present:\n",
    "        if c in df.columns:\n",
    "            report(df[c] < 0, c, 'negative_value')\n",
    "\n",
    "    return pd.DataFrame(issues, columns=['row_idx','column','rule','value'])\n"
   ],
   "id": "7c2afc37e29803c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_ames(csv_path: str,\n",
    "               test_size: float = 0.2,\n",
    "               random_state: int = 42,\n",
    "               return_meta: bool = False,\n",
    "               use_rare_bucket: bool = False,\n",
    "               winsorize: bool = False,\n",
    "               drop_exact_duplicates: bool = True,\n",
    "               drop_audit_flags: bool = True):\n",
    "    \"\"\"\n",
    "    Deterministic, leak-free cleaning. Outlier trimming is OFF by default (see train_band_filter).\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_csv(csv_path, sep=\"\\t\")\n",
    "    meta = {'n_raw': len(df_raw), 'na_raw_top': df_raw.isna().sum().sort_values(ascending=False).head(10)}\n",
    "\n",
    "    # ---- Safe pre-split steps\n",
    "    df = df_raw.copy()\n",
    "    df = normalize_categoricals(df)\n",
    "    df = apply_absence_labels(df)\n",
    "    df = fix_basement_consistency(df)\n",
    "    df = consolidate_garage_absence(df)\n",
    "    df = enforce_nonnegative(df)\n",
    "\n",
    "    if drop_exact_duplicates:\n",
    "        before = len(df); df = df.drop_duplicates().copy(); meta['n_dropped_dupes'] = before - len(df)\n",
    "\n",
    "    n_before_time = len(df)\n",
    "    df = apply_time_filters(df)\n",
    "    meta['n_after_time'] = len(df); meta['n_dropped_time'] = n_before_time - meta['n_after_time']\n",
    "\n",
    "    df = add_binary_flags(df)\n",
    "    df = drop_low_signal_columns(df)\n",
    "\n",
    "    if use_rare_bucket:\n",
    "        nominal_candidates = ['MS SubClass','MS Zoning','Neighborhood','Condition 1','Bldg Type','House Style',\n",
    "                              'Roof Style','Exterior 1st','Exterior 2nd','Mas Vnr Type','Foundation','Lot Config',\n",
    "                              'Land Contour','Garage Type','Sale Type','Sale Condition']\n",
    "        nominal_cols = [c for c in nominal_candidates if c in df.columns]\n",
    "        df = bucket_rare(df, nominal_cols, min_count=5)\n",
    "\n",
    "    df = ordinal_encode_inplace(df)\n",
    "\n",
    "    # Drop IDs\n",
    "    df = df.drop(columns=['Order','PID'], errors='ignore')\n",
    "\n",
    "    # ---- Split early (avoid leakage)\n",
    "    train_idx, test_idx = train_test_split(df.index, test_size=test_size, random_state=random_state)\n",
    "    df_tr = df.loc[train_idx].copy(); df_te = df.loc[test_idx].copy()\n",
    "\n",
    "    # ---- Train-only stats, apply to both\n",
    "    stats = compute_train_stats(df_tr)\n",
    "    df_tr = apply_train_stats(df_tr, stats); df_te = apply_train_stats(df_te, stats)\n",
    "\n",
    "    # Not-present numerics → 0 (+indicator)\n",
    "    df_tr = fill_not_present_numerics(df_tr); df_te = fill_not_present_numerics(df_te)\n",
    "\n",
    "    # (optional) winsorization — *feature* numerics only (no target)\n",
    "    if winsorize:\n",
    "        num_cols_tr = [c for c in df_tr.select_dtypes(include=[np.number]).columns if c != 'SalePrice']\n",
    "        q_lo = df_tr[num_cols_tr].quantile(0.01); q_hi = df_tr[num_cols_tr].quantile(0.99)\n",
    "        for c in num_cols_tr:\n",
    "            df_tr[c] = df_tr[c].clip(lower=q_lo.get(c, df_tr[c].min()), upper=q_hi.get(c, df_tr[c].max()))\n",
    "            if c in df_te.columns:\n",
    "                lo = q_lo.get(c, df_tr[c].min()); hi = q_hi.get(c, df_tr[c].max())\n",
    "                df_te[c] = df_te[c].clip(lower=lo, upper=hi)\n",
    "\n",
    "    # Remaining numerics → train medians\n",
    "    df_tr = fill_remaining_numerics_with_train_median(df_tr, stats['num_medians'])\n",
    "    df_te = fill_remaining_numerics_with_train_median(df_te, stats['num_medians'])\n",
    "\n",
    "    # Reset index\n",
    "    df_tr = df_tr.reset_index(drop=True); df_te = df_te.reset_index(drop=True)\n",
    "\n",
    "    # Meta checks (report needs the flags present)\n",
    "    meta['n_fix_bsmt_exposure'] = int(df.get('Fix_BsmtExposure', pd.Series(0)).sum())\n",
    "    all_clean = pd.concat([df_tr, df_te], ignore_index=True)\n",
    "    parts = ['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF']; total = 'Total Bsmt SF'\n",
    "    meta['post_clean_bsmt_mismatch'] = (int((all_clean[total] != all_clean[parts].fillna(0).sum(axis=1)).sum())\n",
    "                                        if all(c in all_clean.columns for c in parts+[total]) else None)\n",
    "    meta['na_clean_top'] = all_clean.isna().sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "    # Validation report (non-fatal)\n",
    "    meta['validation_issues_train'] = validate_dataset(df_tr).head(15)\n",
    "    meta['validation_issues_test']  = validate_dataset(df_te).head(15)\n",
    "\n",
    "    # --- Drop audit flags after meta/report, if requested\n",
    "    if drop_audit_flags:\n",
    "        audit_cols = ['Fix_BsmtExposure', 'Fix_Garage']  # Fix_Garage may not exist\n",
    "        df_tr = df_tr.drop(columns=[c for c in audit_cols if c in df_tr.columns], errors='ignore')\n",
    "        df_te = df_te.drop(columns=[c for c in audit_cols if c in df_te.columns], errors='ignore')\n",
    "\n",
    "    if return_meta:\n",
    "        return df_tr, df_te, meta\n",
    "    return df_tr, df_te"
   ],
   "id": "5a76de5fbe9a8992",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "def train_band_filter(df_tr: pd.DataFrame,\n",
    "                      x_col: str = 'Gr Liv Area',\n",
    "                      y_col: str = 'SalePrice',\n",
    "                      low_q: float = 0.10,\n",
    "                      high_q: float = 0.90):\n",
    "    \"\"\"\n",
    "    Return a row mask for TRAIN keeping only points within [low_q, high_q]\n",
    "    conditional quantile band of log(y) ~ log(x). Uses sklearn QuantileRegressor.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "    x = np.log1p(df_tr[x_col].clip(lower=0)).values.reshape(-1, 1)\n",
    "    y = np.log1p(df_tr[y_col].clip(lower=0)).values\n",
    "    qr_low  = QuantileRegressor(quantile=low_q, alpha=0).fit(x, y)\n",
    "    qr_high = QuantileRegressor(quantile=high_q, alpha=0).fit(x, y)\n",
    "    y_pred_lo = qr_low.predict(x); y_pred_hi = qr_high.predict(x)\n",
    "    keep_mask = (y >= y_pred_lo) & (y <= y_pred_hi)\n",
    "    return keep_mask\n"
   ],
   "id": "1db0d970c82fe727",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Cleaning only (no outlier trimming)\n",
    "    df_train_20, df_test_20, meta_20 = clean_ames(\n",
    "        \"AmesHousing.csv\",\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        return_meta=True,\n",
    "        use_rare_bucket=False,   # stays OFF (safe)\n",
    "        winsorize=False,         # stays OFF (modeling choice)\n",
    "        drop_exact_duplicates=True,\n",
    "        drop_audit_flags=True    # <— recommended ON for modeling\n",
    "    )\n",
    "    print(\"Train 20% shape:\", df_train_20.shape, \"Test 20% shape:\", df_test_20.shape)\n",
    "\n",
    "    # Report + quick plots\n",
    "    generate_sanity_report(\n",
    "        df_raw=pd.read_csv(\"AmesHousing.csv\", sep=\"\\t\"),\n",
    "        df_train_clean=df_train_20,\n",
    "        df_test_clean=df_test_20,\n",
    "        meta=meta_20,\n",
    "        make_plots=True\n",
    "    )\n",
    "\n",
    "    # OPTIONAL: TRAIN-ONLY trimming (leak-free)\n",
    "    # keep_mask = train_band_filter(df_train_20, x_col='Gr Liv Area', y_col='SalePrice', low_q=0.10, high_q=0.90)\n",
    "    # df_train_band = df_train_20.loc[keep_mask].reset_index(drop=True)\n",
    "    # print(f\"Band-kept rows: {keep_mask.sum()} / {len(keep_mask)} ({keep_mask.mean()*100:.1f}%)\")"
   ],
   "id": "39e1cfa3c7bba9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " Dataset overview\n",
    "\n",
    "- Raw rows: 2930\n",
    "- After temporal filters: 2767 rows\n",
    "  → Dropped 163 rows (5.56%)\n",
    "  → Reason: impossible chronology (Year Built, Year Remod/Add, Yr Sold, or Garage Yr Blt inconsistent)\n",
    "\n",
    "- Train/Test split:\n",
    "  - Train: 2213 rows\n",
    "  - Test: 554 rows\n",
    "  - Columns: 89 each\n",
    "\n",
    "Temporal consistency filters\n",
    "\n",
    "- Yr Sold ≥ Year Built\n",
    "- Yr Sold ≥ Year Remod/Add\n",
    "- Year Remod/Add ≥ Year Built\n",
    "- Garage Yr Blt between 1880 and Yr Sold + 1\n",
    "\n",
    "→ 163 rows removed (~5.56%) because they violated at least one rule.\n",
    "\n",
    " Basement consistency fixes\n",
    "\n",
    "- 3 rows corrected where Bsmt Exposure was “NoBasement” but basement area > 0.\n",
    "  These were changed to “No” and flagged in Fix_BsmtExposure.\n",
    "\n",
    "- Checked identity:\n",
    "  Total Bsmt SF == BsmtFin SF 1 + BsmtFin SF 2 + Bsmt Unf SF\n",
    "  → 0 mismatches after cleaning.\n",
    "\n",
    " Missing data profile\n",
    "\n",
    " Before cleaning (top 10 columns with missing values)\n",
    "\n",
    "| Column | Missing count |\n",
    "|:--|--:|\n",
    "| Pool QC | 2917 |\n",
    "| Misc Feature | 2824 |\n",
    "| Alley | 2732 |\n",
    "| Fence | 2358 |\n",
    "| Mas Vnr Type | 1775 |\n",
    "| Fireplace Qu | 1422 |\n",
    "| Lot Frontage | 490 |\n",
    "| Garage Qual | 159 |\n",
    "| Garage Yr Blt | 159 |\n",
    "| Garage Cond | 159 |\n",
    "\n",
    "Most missing values correspond to optional features (pools, fences, alleys).\n",
    "These were replaced with explicit absence labels like “NoPool”, “NoFence”, “NoGarage”, etc.\n",
    "\n",
    "### After cleaning (top 10 columns with missing values)\n",
    "\n",
    "| Column | Missing count |\n",
    "|:--|--:|\n",
    "| MS SubClass | 0 |\n",
    "| MS Zoning | 0 |\n",
    "| Lot Frontage | 0 |\n",
    "| Lot Area | 0 |\n",
    "| Alley | 0 |\n",
    "| Lot Shape | 0 |\n",
    "| Land Contour | 0 |\n",
    "| Lot Config | 0 |\n",
    "| Land Slope | 0 |\n",
    "| Neighborhood | 0 |\n",
    "\n",
    "All missing values have been handled.\n",
    "No remaining NaN values in either numeric or categorical columns.\n",
    "\n",
    "SalePrice distribution\n",
    "\n",
    "| Stage | Rows | Median | Min | Max |\n",
    "|:--|--:|--:|--:|--:|\n",
    "| Raw | 2930 | 160000 | 12789 | 755000 |\n",
    "| Cleaned | 2767 | 165000 | 12789 | 755000 |\n",
    "\n",
    "Median increased slightly after filtering (160k → 165k),\n",
    "most likely because invalid or inconsistent low-priced entries were removed.\n",
    "\n",
    "Sanity summary\n",
    "\n",
    "| Check | Status | Notes |\n",
    "|:--|:--|:--|\n",
    "| Temporal logic | OK | 163 invalid rows removed |\n",
    "| Basement identity | OK | Totals match parts |\n",
    "| Garage logic | OK | Invalid years and NaNs fixed |\n",
    "| Missing data | OK | All filled logically |\n",
    "| Outliers | To do | Will be handled later (train-only quantile band) |\n",
    "| Leakage | None | Train/test split before computing stats |\n",
    "| Dataset balance | OK | 80/20 split consistent |\n",
    "\n",
    "DONE\n",
    "\n",
    "* TODO Outlier filtering can be applied later using `train_band_filter()` if needed.*"
   ],
   "id": "b709ba44151a1e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os, sys, platform, json, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "RANDOM_STATE = 42"
   ],
   "id": "60befea5e23b052c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 0.2 — load & clean (lock splits for A and B)\n",
    "\n",
    "DATA_PATH = \"AmesHousing.csv\"  # tab-separated\n",
    "assert os.path.exists(DATA_PATH), f\"File not found: {DATA_PATH}\"\n",
    "\n",
    "# Scenario A (80/20)\n",
    "df_train_A, df_test_A, meta_A = clean_ames(\n",
    "    DATA_PATH,\n",
    "    test_size=0.20,\n",
    "    random_state=RANDOM_STATE,\n",
    "    return_meta=True,\n",
    "    use_rare_bucket=False,\n",
    "    winsorize=False,\n",
    "    drop_exact_duplicates=True,\n",
    "    drop_audit_flags=True\n",
    ")\n",
    "\n",
    "# Scenario B (90/10)\n",
    "df_train_B, df_test_B, meta_B = clean_ames(\n",
    "    DATA_PATH,\n",
    "    test_size=0.10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    return_meta=True,\n",
    "    use_rare_bucket=False,\n",
    "    winsorize=False,\n",
    "    drop_exact_duplicates=True,\n",
    "    drop_audit_flags=True\n",
    ")\n",
    "\n",
    "print(\"A — shapes:\", df_train_A.shape, df_test_A.shape)\n",
    "print(\"B — shapes:\", df_train_B.shape, df_test_B.shape)\n"
   ],
   "id": "11df9dd20d109800",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 0.3 — assertions for both scenarios\n",
    "\n",
    "def assert_no_nans(df, name):\n",
    "    nans = df.isna().sum().sum()\n",
    "    assert nans == 0, f\"{name} still has {nans} NaNs\"\n",
    "    return True\n",
    "\n",
    "def assert_same_columns(df_tr, df_te, tag):\n",
    "    c1, c2 = list(df_tr.columns), list(df_te.columns)\n",
    "    assert c1 == c2, f\"{tag}: train/test columns differ!\"\n",
    "    return True\n",
    "\n",
    "def feature_count_ok(df, approx=89):\n",
    "    n = df.shape[1]\n",
    "    print(f\"- Feature count = {n} (expected ≈ {approx})\")\n",
    "    return n\n",
    "\n",
    "print(\"Scenario A checks:\")\n",
    "assert_no_nans(df_train_A, \"train_A\"); assert_no_nans(df_test_A, \"test_A\")\n",
    "assert_same_columns(df_train_A, df_test_A, \"A\")\n",
    "nA = feature_count_ok(df_train_A)\n",
    "\n",
    "print(\"\\nScenario B checks:\")\n",
    "assert_no_nans(df_train_B, \"train_B\"); assert_no_nans(df_test_B, \"test_B\")\n",
    "assert_same_columns(df_train_B, df_test_B, \"B\")\n",
    "nB = feature_count_ok(df_train_B)\n",
    "\n",
    "# Quick expected shape sanity (non-fatal)\n",
    "print(\"\\n(Non-fatal) Expected shape hints:\")\n",
    "print(\"- A ~ (2213, 89) train / (554, 89) test\")\n",
    "print(\"- B ~ (2490, 89) train / (277, 89) test\")\n",
    "\n",
    "print(\"\\nAll Step 0.3 assertions passed!!\")\n"
   ],
   "id": "8bd6da8140e15112",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 0.4 — save frozen splits and metadata\n",
    "\n",
    "OUT_DIR = \"L2_artifacts\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Data splits (CSV to avoid parquet deps)\n",
    "df_train_A.to_csv(os.path.join(OUT_DIR, \"L2_clean_train_A.csv\"), index=False)\n",
    "df_test_A .to_csv(os.path.join(OUT_DIR, \"L2_clean_test_A.csv\"),  index=False)\n",
    "df_train_B.to_csv(os.path.join(OUT_DIR, \"L2_clean_train_B.csv\"), index=False)\n",
    "df_test_B .to_csv(os.path.join(OUT_DIR, \"L2_clean_test_B.csv\"),  index=False)\n",
    "\n",
    "# Meta objects can contain Series/DataFrames; pickle them safely\n",
    "with open(os.path.join(OUT_DIR, \"meta_A.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(meta_A, f)\n",
    "with open(os.path.join(OUT_DIR, \"meta_B.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(meta_B, f)\n",
    "\n",
    "# Feature registry (exclude SalePrice for now; PriceClass will be created in Step 1)\n",
    "feature_names = [c for c in df_train_A.columns if c != \"SalePrice\"]\n",
    "with open(os.path.join(OUT_DIR, \"feature_names.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sorted(feature_names), f, indent=2)\n",
    "\n",
    "# Nice one-screen summary\n",
    "def rows_after_filters(meta):\n",
    "    return meta.get(\"n_after_time\", None)\n",
    "\n",
    "summary = {\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"scenario_A\": {\n",
    "        \"train_shape\": df_train_A.shape,\n",
    "        \"test_shape\":  df_test_A.shape,\n",
    "        \"n_features\":  df_train_A.shape[1],\n",
    "        \"rows_after_temporal_filters\": rows_after_filters(meta_A),\n",
    "    },\n",
    "    \"scenario_B\": {\n",
    "        \"train_shape\": df_train_B.shape,\n",
    "        \"test_shape\":  df_test_B.shape,\n",
    "        \"n_features\":  df_train_B.shape[1],\n",
    "        \"rows_after_temporal_filters\": rows_after_filters(meta_B),\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, \"step0_summary.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "for fn in [\n",
    "    \"L2_clean_train_A.csv\",\"L2_clean_test_A.csv\",\n",
    "    \"L2_clean_train_B.csv\",\"L2_clean_test_B.csv\",\n",
    "    \"meta_A.pkl\",\"meta_B.pkl\",\n",
    "    \"feature_names.json\",\"step0_summary.json\"\n",
    "]:\n",
    "    print(\" -\", os.path.join(OUT_DIR, fn))\n",
    "\n",
    "print(\"\\nStep 0 is complete and splits are FROZEN.\")\n"
   ],
   "id": "dacefea7ad4c4569",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 0.5 — compact summary printout\n",
    "\n",
    "def compact_meta(meta):\n",
    "    n_raw = meta.get(\"n_raw\", None)\n",
    "    n_after = meta.get(\"n_after_time\", None)\n",
    "    dropped = None if (n_raw is None or n_after is None) else (n_raw - n_after)\n",
    "    pct = None if (n_raw in (None, 0) or n_after is None) else 100.0 * dropped / n_raw\n",
    "    return f\"raw={n_raw}, after_filters={n_after}, dropped={dropped} ({pct:.2f}%)\"\n",
    "\n",
    "print(\"Scenario A:\", summary[\"scenario_A\"])\n",
    "print(\"Meta A:\", compact_meta(meta_A))\n",
    "\n",
    "print(\"\\nScenario B:\", summary[\"scenario_B\"])\n",
    "print(\"Meta B:\", compact_meta(meta_B))\n",
    "\n",
    "print(\"\\nNote: From now on, always reload from L2_artifacts/* for fair comparisons.\")\n"
   ],
   "id": "29439d83e0712d56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1.0 — config & load frozen splits\n",
    "ART_IN  = \"L2_artifacts\"   # from Step 0\n",
    "ART_OUT = \"L3_artifacts\"   # new folder for Step 1\n",
    "os.makedirs(ART_OUT, exist_ok=True)\n",
    "\n",
    "# Load Step 0 splits (Scenario A = 80/20, Scenario B = 90/10)\n",
    "df_train_A = pd.read_csv(os.path.join(ART_IN, \"L2_clean_train_A.csv\"))\n",
    "df_test_A  = pd.read_csv(os.path.join(ART_IN, \"L2_clean_test_A.csv\"))\n",
    "df_train_B = pd.read_csv(os.path.join(ART_IN, \"L2_clean_train_B.csv\"))\n",
    "df_test_B  = pd.read_csv(os.path.join(ART_IN, \"L2_clean_test_B.csv\"))"
   ],
   "id": "5b318882318ca6c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1.1 — leakage-safe quantile binning\n",
    "def make_price_classes(train_df: pd.DataFrame,\n",
    "                       test_df: pd.DataFrame,\n",
    "                       n_bins: int = 5,\n",
    "                       price_col: str = \"SalePrice\",\n",
    "                       label_name: str = \"PriceClass\"):\n",
    "    \"\"\"\n",
    "    Create discrete price classes from SalePrice using TRAIN-only quantile cuts,\n",
    "    then apply the same bin edges to TEST. Returns (train_df2, test_df2, bin_edges).\n",
    "\n",
    "    - n_bins: e.g., 3 (low/med/high), 4 (quartiles), 5 (quintiles).\n",
    "    - Adds both an integer label (PriceClass) and the interval text (PriceClassInterval).\n",
    "    \"\"\"\n",
    "    # Compute bin edges on TRAIN ONLY (drop duplicates so qcut doesn't complain)\n",
    "    q = np.linspace(0, 1, n_bins + 1)\n",
    "    edges = train_df[price_col].quantile(q).values\n",
    "    # Ensure strictly increasing edges (handle equal quantiles in heavy ties)\n",
    "    edges = np.unique(edges)\n",
    "    if len(edges) - 1 < n_bins:\n",
    "        # Fallback: make slightly ittered edges if too many ties\n",
    "        edges = np.linspace(train_df[price_col].min(), train_df[price_col].max(), n_bins + 1)\n",
    "\n",
    "    # Label on TRAIN\n",
    "    train_df = train_df.copy()\n",
    "    train_df[label_name] = pd.cut(train_df[price_col], bins=edges, include_lowest=True, labels=False)\n",
    "    train_df[\"PriceClassInterval\"] = pd.cut(train_df[price_col], bins=edges, include_lowest=True).astype(str)\n",
    "\n",
    "    # Apply same edges to TEST\n",
    "    test_df = test_df.copy()\n",
    "    test_df[label_name] = pd.cut(test_df[price_col], bins=edges, include_lowest=True, labels=False)\n",
    "    test_df[\"PriceClassInterval\"] = pd.cut(test_df[price_col], bins=edges, include_lowest=True).astype(str)\n",
    "\n",
    "    # In rare cases values may fall outside due to numeric eps — clip & relabel\n",
    "    train_df[label_name] = train_df[label_name].astype(\"Int64\")\n",
    "    test_df[label_name]  = test_df[label_name].astype(\"Int64\")\n",
    "\n",
    "    # Safety assertions (no NaNs in labels)\n",
    "    assert train_df[label_name].isna().sum() == 0, \"Train has NaNs in PriceClass\"\n",
    "    assert test_df[label_name].isna().sum() == 0, \"Test has NaNs in PriceClass\"\n",
    "\n",
    "    return train_df, test_df, edges\n"
   ],
   "id": "4f27ace48da07344",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1.2 — create 5-class target (quintiles) for A and B\n",
    "N_BINS = 5  # 3/4 the recall and precision are getting lower the trees deeper and there number >>>\n",
    "\n",
    "trA_cls, teA_cls, edges_A = make_price_classes(df_train_A, df_test_A, n_bins=N_BINS)\n",
    "trB_cls, teB_cls, edges_B = make_price_classes(df_train_B, df_test_B, n_bins=N_BINS)\n",
    "\n",
    "print(\"Scenario A — PriceClass value counts (train):\")\n",
    "print(trA_cls[\"PriceClass\"].value_counts(normalize=True).sort_index().round(3))\n",
    "\n",
    "print(\"\\nScenario B — PriceClass value counts (train):\")\n",
    "print(trB_cls[\"PriceClass\"].value_counts(normalize=True).sort_index().round(3))\n",
    "\n",
    "print(\"\\nBin edges A:\", edges_A)\n",
    "print(\"Bin edges B:\", edges_B)"
   ],
   "id": "c764babb0bcd5c66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1.3 — sanity checks for stratification-like balance across splits\n",
    "def class_share(df, label=\"PriceClass\"):\n",
    "    s = df[label].value_counts(normalize=True).sort_index()\n",
    "    return s.rename(lambda k: f\"C{k}\")\n",
    "\n",
    "print(\"A — train shares:\\n\", class_share(trA_cls))\n",
    "print(\"\\nA — test  shares:\\n\", class_share(teA_cls))\n",
    "\n",
    "print(\"\\nB — train shares:\\n\", class_share(trB_cls))\n",
    "print(\"\\nB — test  shares:\\n\", class_share(teB_cls))\n",
    "\n",
    "# Same label set?\n",
    "assert set(trA_cls[\"PriceClass\"].unique()) == set(teA_cls[\"PriceClass\"].unique()), \"A: class mismatch train/test\"\n",
    "assert set(trB_cls[\"PriceClass\"].unique()) == set(teB_cls[\"PriceClass\"].unique()), \"B: class mismatch train/test\"\n",
    "print(\"\\nLabel sets match in A and B\")"
   ],
   "id": "673f38cca7af0506",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1.4 — show SalePrice medians by class (interpretability check)\n",
    "def price_summary(df):\n",
    "    return df.groupby(\"PriceClass\")[\"SalePrice\"].agg([\"count\",\"median\",\"min\",\"max\"]).astype(int)\n",
    "\n",
    "print(\"A — train price by class:\\n\", price_summary(trA_cls))\n",
    "print(\"\\nA — test  price by class:\\n\", price_summary(teA_cls))\n",
    "\n",
    "print(\"\\nB — train price by class:\\n\", price_summary(trB_cls))\n",
    "print(\"\\nB — test  price by class:\\n\", price_summary(teB_cls))"
   ],
   "id": "e6e02acef4872941",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1.5 — persist L3 artifacts\n",
    "trA_cls.to_csv(os.path.join(ART_OUT, \"L3_cls_train_A.csv\"), index=False)\n",
    "teA_cls.to_csv(os.path.join(ART_OUT, \"L3_cls_test_A.csv\"),  index=False)\n",
    "trB_cls.to_csv(os.path.join(ART_OUT, \"L3_cls_train_B.csv\"), index=False)\n",
    "teB_cls.to_csv(os.path.join(ART_OUT, \"L3_cls_test_B.csv\"),  index=False)\n",
    "\n",
    "# Save bin edges for reproducibility\n",
    "with open(os.path.join(ART_OUT, \"L3_edges_A.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump([float(x) for x in edges_A], f, indent=2)\n",
    "with open(os.path.join(ART_OUT, \"L3_edges_B.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump([float(x) for x in edges_B], f, indent=2)\n",
    "\n",
    "# Save a tiny registry of the new label name\n",
    "with open(os.path.join(ART_OUT, \"L3_label_meta.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"label_name\": \"PriceClass\",\n",
    "        \"interval_col\": \"PriceClassInterval\",\n",
    "        \"n_bins\": int(N_BINS),\n",
    "        \"note\": \"Bins computed on TRAIN only; applied to TEST without refit.\"\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved Step 1 artifacts in:\", ART_OUT)\n",
    "for fn in [\"L3_cls_train_A.csv\",\"L3_cls_test_A.csv\",\"L3_edges_A.json\",\n",
    "           \"L3_cls_train_B.csv\",\"L3_cls_test_B.csv\",\"L3_edges_B.json\",\n",
    "           \"L3_label_meta.json\"]:\n",
    "    print(\" -\", os.path.join(ART_OUT, fn))\n",
    "print(\"\\nStep 1 complete.\")\n"
   ],
   "id": "ce1d43f205141de8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "ART_IN  = \"L3_artifacts\"   # created in Step 1\n",
    "ART_OUT = \"L4_artifacts\"   # new folder for Step 2\n",
    "os.makedirs(ART_OUT, exist_ok=True)\n",
    "\n",
    "# Scenario A (80/20)\n",
    "trA = pd.read_csv(os.path.join(ART_IN, \"L3_cls_train_A.csv\"))\n",
    "teA = pd.read_csv(os.path.join(ART_IN, \"L3_cls_test_A.csv\"))\n",
    "\n",
    "# Scenario B (90/10)\n",
    "trB = pd.read_csv(os.path.join(ART_IN, \"L3_cls_train_B.csv\"))\n",
    "teB = pd.read_csv(os.path.join(ART_IN, \"L3_cls_test_B.csv\"))\n",
    "\n",
    "# Optional: Show quick shapes\n",
    "print(\"A:\", trA.shape, teA.shape)\n",
    "print(\"B:\", trB.shape, teB.shape)\n"
   ],
   "id": "7462be2775bf2000",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2.1 — define X and y\n",
    "LABEL_COL = \"PriceClass\"\n",
    "DROP_FROM_X = [LABEL_COL, \"SalePrice\", \"PriceClassInterval\"]  # interval text exists after Step 1\n",
    "\n",
    "def split_xy(df: pd.DataFrame):\n",
    "    cols_x = [c for c in df.columns if c not in DROP_FROM_X]\n",
    "    X = df[cols_x].copy()\n",
    "    y = df[LABEL_COL].astype(\"int64\").copy()\n",
    "    return X, y, cols_x\n",
    "\n",
    "XA_tr, yA_tr, colsA = split_xy(trA)\n",
    "XA_te, yA_te, _     = split_xy(teA)\n",
    "\n",
    "XB_tr, yB_tr, colsB = split_xy(trB)\n",
    "XB_te, yB_te, _     = split_xy(teB)\n",
    "\n",
    "print(\"A — X cols:\", len(colsA), \"| y classes:\", sorted(yA_tr.unique()))\n",
    "print(\"B — X cols:\", len(colsB), \"| y classes:\", sorted(yB_tr.unique()))\n"
   ],
   "id": "6383538d8927ea4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2.2 — dtype audit\n",
    "def dtype_report(X, tag):\n",
    "    rep = X.dtypes.value_counts()\n",
    "    obj_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    print(f\"\\n{tag} dtypes:\\n{rep}\")\n",
    "    if obj_cols:\n",
    "        print(f\"{tag} object columns needing OHE: {obj_cols}\")\n",
    "    else:\n",
    "        print(f\"{tag}: no object columns — already numeric\")\n",
    "\n",
    "dtype_report(XA_tr, \"A_train\")\n",
    "dtype_report(XA_te, \"A_test\")\n",
    "dtype_report(XB_tr, \"B_train\")\n",
    "dtype_report(XB_te, \"B_test\")\n"
   ],
   "id": "ea0017898bdf1a6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2.3 — OHE for object cols (fit on TRAIN), passthrough numeric\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def make_preprocessor(X_train: pd.DataFrame):\n",
    "    obj_cols = X_train.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "    num_cols = [c for c in X_train.columns if c not in obj_cols]\n",
    "\n",
    "    if obj_cols:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, dtype=np.float64)\n",
    "        pre = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"cat\", ohe, obj_cols),\n",
    "                (\"num\", \"passthrough\", num_cols),\n",
    "            ],\n",
    "            remainder=\"drop\",\n",
    "            verbose_feature_names_out=False,\n",
    "        )\n",
    "    else:\n",
    "        # no object columns; identity transformer on all\n",
    "        pre = ColumnTransformer(\n",
    "            transformers=[(\"num\", \"passthrough\", X_train.columns.tolist())],\n",
    "            remainder=\"drop\",\n",
    "            verbose_feature_names_out=False,\n",
    "        )\n",
    "    return pre\n",
    "\n",
    "def fit_transform_splits(X_train, X_test):\n",
    "    Xtr = X_train.copy()\n",
    "    Xte = X_test.copy()\n",
    "\n",
    "    obj_cols = Xtr.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "    for c in obj_cols:\n",
    "        Xtr[c] = Xtr[c].astype(str)\n",
    "        if c in Xte.columns:\n",
    "            Xte[c] = Xte[c].astype(str)\n",
    "\n",
    "    pre = make_preprocessor(Xtr)\n",
    "    Xtr_m = pre.fit_transform(Xtr)\n",
    "    Xte_m = pre.transform(Xte)\n",
    "    feat_names = pre.get_feature_names_out().tolist()\n",
    "    return Xtr_m, Xte_m, feat_names, pre\n",
    "\n",
    "# Scenario A\n",
    "XA_tr_m, XA_te_m, featA, preA = fit_transform_splits(XA_tr, XA_te)\n",
    "print(\"A transformed shapes:\", XA_tr_m.shape, XA_te_m.shape)\n",
    "\n",
    "# Scenario B\n",
    "XB_tr_m, XB_te_m, featB, preB = fit_transform_splits(XB_tr, XB_te)\n",
    "print(\"B transformed shapes:\", XB_tr_m.shape, XB_te_m.shape)\n"
   ],
   "id": "7d622e0afe78d72e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2.4 — persist arrays and metadata for modeling\n",
    "\n",
    "# Arrays (npz)\n",
    "np.savez_compressed(os.path.join(ART_OUT, \"A_data.npz\"),\n",
    "                    X_train=XA_tr_m, y_train=yA_tr.values,\n",
    "                    X_test=XA_te_m, y_test=yA_te.values)\n",
    "np.savez_compressed(os.path.join(ART_OUT, \"B_data.npz\"),\n",
    "                    X_train=XB_tr_m, y_train=yB_tr.values,\n",
    "                    X_test=XB_te_m, y_test=yB_te.values)\n",
    "\n",
    "# Feature names\n",
    "with open(os.path.join(ART_OUT, \"A_features.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(featA, f, indent=2)\n",
    "with open(os.path.join(ART_OUT, \"B_features.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(featB, f, indent=2)\n",
    "\n",
    "# Save preprocessors (so tree/importance later can be mapped back reliably)\n",
    "with open(os.path.join(ART_OUT, \"A_preprocessor.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(preA, f)\n",
    "with open(os.path.join(ART_OUT, \"B_preprocessor.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(preB, f)\n",
    "\n",
    "# Quick summaries\n",
    "def class_share(y):\n",
    "    vc = pd.Series(y).value_counts(normalize=True).sort_index().round(3)\n",
    "    return vc.rename(lambda k: f\"C{k}\")\n",
    "\n",
    "print(\"\\nSaved to:\", ART_OUT)\n",
    "print(\"A — y_train shares:\\n\", class_share(yA_tr))\n",
    "print(\"A — y_test  shares:\\n\", class_share(yA_te))\n",
    "print(\"\\nB — y_train shares:\\n\", class_share(yB_tr))\n",
    "print(\"B — y_test  shares:\\n\", class_share(yB_te))\n"
   ],
   "id": "cb2ee7ea60b4bf72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 4.0 — imports + load arrays\n",
    "import os, json, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier, plot_tree, plot_importance\n",
    "\n",
    "ART_IN = \"L4_artifacts\"\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "# Load Scenario A\n",
    "A = np.load(os.path.join(ART_IN, \"A_data.npz\"))\n",
    "XA_tr, yA_tr = A[\"X_train\"], A[\"y_train\"]\n",
    "XA_te, yA_te = A[\"X_test\"],  A[\"y_test\"]\n",
    "\n",
    "# Load Scenario B\n",
    "B = np.load(os.path.join(ART_IN, \"B_data.npz\"))\n",
    "XB_tr, yB_tr = B[\"X_train\"], B[\"y_train\"]\n",
    "XB_te, yB_te = B[\"X_test\"],  B[\"y_test\"]\n",
    "\n",
    "print(\"A:\", XA_tr.shape, XA_te.shape)\n",
    "print(\"B:\", XB_tr.shape, XB_te.shape)\n"
   ],
   "id": "24e10635b03c479b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 4.1 — baseline XGBoost for A and B (clean params)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "N_CLASSES = len(np.unique(yA_tr))  # same for B in our setup\n",
    "\n",
    "BASE_PARAMS = dict(\n",
    "    objective=\"multi:softprob\",      # multiclass probabilities\n",
    "    eval_metric=\"mlogloss\",          # you can also add \"merror\" to see error rate\n",
    "    random_state=42,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=1.0,\n",
    "    # optional but explicit:\n",
    "    num_class=N_CLASSES,\n",
    "    # optional speedups:\n",
    "    tree_method=\"hist\",              # or \"gpu_hist\" if you have a GPU\n",
    "    verbosity=0                      # quieten training logs\n",
    ")\n",
    "\n",
    "model_A = XGBClassifier(**BASE_PARAMS)\n",
    "model_B = XGBClassifier(**BASE_PARAMS)\n",
    "\n",
    "print(\"Training Scenario A (80/20)...\")\n",
    "model_A.fit(XA_tr, yA_tr)\n",
    "\n",
    "print(\"Training Scenario B (90/10)...\")\n",
    "model_B.fit(XB_tr, yB_tr)\n"
   ],
   "id": "62a4526bb3549a3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 4.2 — compute metrics and reports\n",
    "def evaluate_model(model, Xtr, ytr, Xte, yte, tag):\n",
    "    print(f\"\\n=== {tag} Results ===\")\n",
    "    y_pred = model.predict(Xte)\n",
    "    acc  = accuracy_score(yte, y_pred)\n",
    "    prec = precision_score(yte, y_pred, average=\"macro\")\n",
    "    rec  = recall_score(yte, y_pred, average=\"macro\")\n",
    "    f1   = f1_score(yte, y_pred, average=\"macro\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Precision: {prec:.3f} | Recall: {rec:.3f} | F1: {f1:.3f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(yte, y_pred, digits=3))\n",
    "    cm = confusion_matrix(yte, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm)\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix — {tag}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(model_A, XA_tr, yA_tr, XA_te, yA_te, \"Scenario A (80/20)\")\n",
    "evaluate_model(model_B, XB_tr, yB_tr, XB_te, yB_te, \"Scenario B (90/10)\")\n"
   ],
   "id": "e2c226502fb3822b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 4.3 — robust tree plotting for multiclass (no early stopping)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_tree\n",
    "\n",
    "def plot_some_trees(model, tag, which=(\"first\", \"middle\", \"last\")):\n",
    "    \"\"\"\n",
    "    Plot a few trees from a trained XGBClassifier, handling:\n",
    "    - No early stopping (no best_iteration)\n",
    "    - Multiclass (num_class trees per boosting round)\n",
    "    \"\"\"\n",
    "    booster = model.get_booster()\n",
    "\n",
    "    # Number of boosting rounds actually used:\n",
    "    n_rounds = booster.num_boosted_rounds()  # ok with or without early stopping\n",
    "\n",
    "    # Number of classes (multiclass has one tree per class per round)\n",
    "    try:\n",
    "        n_classes = len(model.classes_)\n",
    "    except Exception:\n",
    "        n_classes = int(booster.attr(\"num_class\") or 1)\n",
    "\n",
    "    total_trees = n_rounds * n_classes\n",
    "\n",
    "    def idx_pick(key):\n",
    "        if key == \"first\":\n",
    "            return 0\n",
    "        if key == \"middle\":\n",
    "            return max(0, total_trees // 2)\n",
    "        if key == \"last\":\n",
    "            return total_trees - 1\n",
    "        # allow explicit numeric index\n",
    "        return int(key)\n",
    "\n",
    "    for key in which:\n",
    "        idx = idx_pick(key)\n",
    "        round_idx = idx // n_classes\n",
    "        class_idx = idx % n_classes\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        # Use tree_idx to avoid FutureWarning on num_trees\n",
    "        plot_tree(model, tree_idx=idx)\n",
    "        plt.title(f\"{tag} — Tree {idx}  (round={round_idx}, class={class_idx})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_some_trees(model_A, \"Scenario A (80/20)\")\n",
    "plot_some_trees(model_B, \"Scenario B (90/10)\")\n"
   ],
   "id": "a9cad4603981be92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 4.4 — feature importance (top 15)\n",
    "with open(os.path.join(\"L4_artifacts\",\"A_features.json\"),\"r\") as f:\n",
    "    featA = json.load(f)\n",
    "with open(os.path.join(\"L4_artifacts\",\"B_features.json\"),\"r\") as f:\n",
    "    featB = json.load(f)\n",
    "\n",
    "def top_importance(model, feature_names, tag, topn=15):\n",
    "    booster = model.get_booster()\n",
    "    imp = booster.get_score(importance_type=\"gain\")\n",
    "    df = pd.DataFrame(list(imp.items()), columns=[\"Feature\",\"Gain\"])\n",
    "    df = df.sort_values(\"Gain\", ascending=False).head(topn)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(df[\"Feature\"], df[\"Gain\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Top {topn} Feature Importances (Gain) — {tag}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return df\n",
    "\n",
    "impA = top_importance(model_A, featA, \"Scenario A\")\n",
    "impB = top_importance(model_B, featB, \"Scenario B\")\n"
   ],
   "id": "dab7c54f9a4002bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 5 — Cross-validation on the training set (A: k=5, B: k=10)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def cv_scores(X, y, k, params):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    rows = []\n",
    "    for fold, (tr, va) in enumerate(skf.split(X, y), 1):\n",
    "        clf = XGBClassifier(**params)\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        yp = clf.predict(X[va])\n",
    "        rows.append({\n",
    "            \"fold\": fold,\n",
    "            \"acc\": accuracy_score(y[va], yp),\n",
    "            \"prec\": precision_score(y[va], yp, average=\"macro\"),\n",
    "            \"rec\":  recall_score(y[va], yp, average=\"macro\"),\n",
    "            \"f1\":   f1_score(y[va], yp, average=\"macro\"),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df, df.mean(numeric_only=True).to_dict()\n",
    "\n",
    "# Use the same BASE_PARAMS you trained with\n",
    "print(\"CV — Scenario A (80/20), k=5\")\n",
    "cvA_df, cvA_mean = cv_scores(XA_tr, yA_tr, k=5, params=BASE_PARAMS)\n",
    "display(cvA_df); print(\"Mean:\", {k: round(v,3) for k, v in cvA_mean.items()})\n",
    "\n",
    "print(\"\\nCV — Scenario B (90/10), k=10\")\n",
    "cvB_df, cvB_mean = cv_scores(XB_tr, yB_tr, k=10, params=BASE_PARAMS)\n",
    "display(cvB_df); print(\"Mean:\", {k: round(v,3) for k, v in cvB_mean.items()})"
   ],
   "id": "766ed48fac884c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 6 — Data-prep strategy comparison\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def run_strategy(tag, test_size, use_rare_bucket=False, winsorize=False, band_filter=False):\n",
    "    # Clean with toggles\n",
    "    df_tr, df_te, meta = clean_ames(\n",
    "        DATA_PATH, test_size=test_size, random_state=RANDOM_STATE,\n",
    "        return_meta=True, use_rare_bucket=use_rare_bucket, winsorize=winsorize,\n",
    "        drop_exact_duplicates=True, drop_audit_flags=True\n",
    "    )\n",
    "\n",
    "    # Make labels (quintiles) on TRAIN only\n",
    "    tr_cls, te_cls, _ = make_price_classes(df_tr, df_te, n_bins=5)\n",
    "\n",
    "    # X/y split\n",
    "    def split_xy(df):\n",
    "        X = df.drop(columns=[\"SalePrice\",\"PriceClass\",\"PriceClassInterval\"], errors=\"ignore\")\n",
    "        y = df[\"PriceClass\"].astype(\"int64\")\n",
    "        return X, y\n",
    "\n",
    "    Xtr, ytr = split_xy(tr_cls); Xte, yte = split_xy(te_cls)\n",
    "\n",
    "    # Build preprocessor from TRAIN and transform\n",
    "    Xtr_m, Xte_m, feats, pre = fit_transform_splits(Xtr, Xte)\n",
    "\n",
    "    # Train XGB baseline\n",
    "    clf = XGBClassifier(**BASE_PARAMS)\n",
    "    clf.fit(Xtr_m, ytr)\n",
    "    yp = clf.predict(Xte_m)\n",
    "\n",
    "    res = {\n",
    "        \"tag\": tag,\n",
    "        \"acc\": accuracy_score(yte, yp),\n",
    "        \"prec\": precision_score(yte, yp, average=\"macro\"),\n",
    "        \"rec\":  recall_score(yte, yp, average=\"macro\"),\n",
    "        \"f1\":   f1_score(yte, yp, average=\"macro\"),\n",
    "        \"n_train\": len(Xtr), \"n_test\": len(Xte)\n",
    "    }\n",
    "\n",
    "    # Optional train-only band filter\n",
    "    if band_filter and {'Gr Liv Area','SalePrice'} <= set(tr_cls.columns):\n",
    "        keep = train_band_filter(tr_cls, 'Gr Liv Area', 'SalePrice', 0.10, 0.90)\n",
    "        tr_band = tr_cls.loc[keep].reset_index(drop=True)\n",
    "        Xtr_b, ytr_b = split_xy(tr_band)\n",
    "        Xtr_bm = pre.fit_transform(Xtr_b)  # refit preprocessor on the trimmed TRAIN\n",
    "        Xte_bm = pre.transform(Xte)\n",
    "        clf_b = XGBClassifier(**BASE_PARAMS)\n",
    "        clf_b.fit(Xtr_bm, ytr_b)\n",
    "        yp_b = clf_b.predict(Xte_bm)\n",
    "        res.update({\n",
    "            \"band_acc\": accuracy_score(yte, yp_b),\n",
    "            \"band_prec\": precision_score(yte, yp_b, average=\"macro\"),\n",
    "            \"band_rec\":  recall_score(yte, yp_b, average=\"macro\"),\n",
    "            \"band_f1\":   f1_score(yte, yp_b, average=\"macro\"),\n",
    "            \"n_train_band\": len(Xtr_b)\n",
    "        })\n",
    "\n",
    "    return SimpleNamespace(**res)\n",
    "\n",
    "results = []\n",
    "# Scenario A (80/20)\n",
    "results.append(run_strategy(\"A: baseline\", 0.20, use_rare_bucket=False, winsorize=False, band_filter=False))\n",
    "results.append(run_strategy(\"A: rare_bucket\", 0.20, use_rare_bucket=True,  winsorize=False, band_filter=False))\n",
    "results.append(run_strategy(\"A: winsorize\",   0.20, use_rare_bucket=False, winsorize=True,  band_filter=False))\n",
    "results.append(run_strategy(\"A: band_filter\", 0.20, use_rare_bucket=False, winsorize=False, band_filter=True))\n",
    "\n",
    "# Scenario B (90/10)\n",
    "results.append(run_strategy(\"B: baseline\", 0.10, use_rare_bucket=False, winsorize=False, band_filter=False))\n",
    "results.append(run_strategy(\"B: rare_bucket\", 0.10, use_rare_bucket=True,  winsorize=False, band_filter=False))\n",
    "results.append(run_strategy(\"B: winsorize\",   0.10, use_rare_bucket=False, winsorize=True,  band_filter=False))\n",
    "results.append(run_strategy(\"B: band_filter\", 0.10, use_rare_bucket=False, winsorize=False, band_filter=True))\n",
    "\n",
    "comp = pd.DataFrame([r.__dict__ for r in results])\n",
    "display(comp.sort_values(\"f1\", ascending=False))"
   ],
   "id": "3137302c0b15d2ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 7 — Manual hyperparameter experiments (gridlite)\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def grid_search_quick(Xtr, ytr, Xte, yte, grid, base=BASE_PARAMS, tag=\"A\"):\n",
    "    rows = []\n",
    "    for p in ParameterGrid(grid):\n",
    "        params = base.copy(); params.update(p)\n",
    "        clf = XGBClassifier(**params)\n",
    "        clf.fit(Xtr, ytr)\n",
    "        yp = clf.predict(Xte)\n",
    "        rows.append({\n",
    "            **p,\n",
    "            \"acc\":  accuracy_score(yte, yp),\n",
    "            \"prec\": precision_score(yte, yp, average=\"macro\"),\n",
    "            \"rec\":  recall_score(yte, yp, average=\"macro\"),\n",
    "            \"f1\":   f1_score(yte, yp, average=\"macro\"),\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"f1\", ascending=False)\n",
    "    print(f\"\\n{tag} — grid results (top):\")\n",
    "    display(df.head(10))\n",
    "    return df\n",
    "\n",
    "grid = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"n_estimators\": [200, 300, 500],\n",
    "}\n",
    "\n",
    "dfA_grid = grid_search_quick(XA_tr, yA_tr, XA_te, yA_te, grid, BASE_PARAMS, tag=\"A (80/20)\")\n",
    "dfB_grid = grid_search_quick(XB_tr, yB_tr, XB_te, yB_te, grid, BASE_PARAMS, tag=\"B (90/10)\")"
   ],
   "id": "b1810141513a2c0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "ART_IN = \"L4_artifacts\"\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "# Load arrays if not already in memory\n",
    "if 'XA_tr' not in globals():\n",
    "    A = np.load(os.path.join(ART_IN, \"A_data.npz\"))\n",
    "    XA_tr, yA_tr = A[\"X_train\"], A[\"y_train\"]\n",
    "    XA_te, yA_te = A[\"X_test\"],  A[\"y_test\"]\n",
    "\n",
    "    B = np.load(os.path.join(ART_IN, \"B_data.npz\"))\n",
    "    XB_tr, yB_tr = B[\"X_train\"], B[\"y_train\"]\n",
    "    XB_te, yB_te = B[\"X_test\"],  B[\"y_test\"]\n",
    "\n",
    "# Feature names (for importances)\n",
    "if 'featA' not in globals():\n",
    "    with open(os.path.join(ART_IN, \"A_features.json\"), \"r\") as f:\n",
    "        featA = json.load(f)\n",
    "    with open(os.path.join(ART_IN, \"B_features.json\"), \"r\") as f:\n",
    "        featB = json.load(f)\n",
    "\n",
    "print(\"A:\", XA_tr.shape, XA_te.shape, \" | B:\", XB_tr.shape, XB_te.shape)\n"
   ],
   "id": "e3242f1672cfc96a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Common LGBM params (multiclass, 5 classes = your quintiles)\n",
    "LGBM_BASE = dict(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=5,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=300,\n",
    "    max_depth=-1,          # leaf-wise growth, unlimited\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "def lgbm_train_evaluate(Xtr, ytr, Xte, yte, tag):\n",
    "    clf = lgb.LGBMClassifier(**LGBM_BASE)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    yp = clf.predict(Xte)\n",
    "    acc  = accuracy_score(yte, yp)\n",
    "    prec = precision_score(yte, yp, average=\"macro\")\n",
    "    rec  = recall_score(yte, yp, average=\"macro\")\n",
    "    f1   = f1_score(yte, yp, average=\"macro\")\n",
    "    print(f\"\\n=== {tag} — LightGBM Baseline ===\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Precision: {prec:.3f} | Recall: {rec:.3f} | F1: {f1:.3f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(yte, yp, digits=3))\n",
    "\n",
    "    cm = confusion_matrix(yte, yp)\n",
    "    ConfusionMatrixDisplay(cm).plot(cmap=\"Purples\")\n",
    "    plt.title(f\"Confusion Matrix — {tag} (LightGBM)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return clf, dict(acc=acc, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "lgbm_A, metrics_A = lgbm_train_evaluate(XA_tr, yA_tr, XA_te, yA_te, \"Scenario A (80/20)\")\n",
    "lgbm_B, metrics_B = lgbm_train_evaluate(XB_tr, yB_tr, XB_te, yB_te, \"Scenario B (90/10)\")\n"
   ],
   "id": "53c9392f5bed494f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lgbm_plot_trees_and_importance(model, feat_names, tag, topn=15):\n",
    "    booster = model.booster_\n",
    "    n_trees = booster.num_trees()\n",
    "\n",
    "    # First tree\n",
    "    ax = lgb.plot_tree(booster, tree_index=0, figsize=(18, 10), show_info=[\"split_gain\",\"internal_value\",\"leaf_count\"])\n",
    "    plt.title(f\"{tag} — First tree (index=0)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Last tree\n",
    "    ax = lgb.plot_tree(booster, tree_index=n_trees-1, figsize=(18, 10), show_info=[\"split_gain\",\"internal_value\",\"leaf_count\"])\n",
    "    plt.title(f\"{tag} — Last tree (index={n_trees-1})\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Feature importances — GAIN (recommended)\n",
    "    gain = pd.Series(booster.feature_importance(importance_type='gain'), index=feat_names)\n",
    "    top_gain = gain.sort_values(ascending=False).head(topn)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    top_gain.plot(kind=\"barh\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"{tag} — Top {topn} Feature Importances (gain) — LightGBM\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "    return top_gain\n",
    "\n",
    "impA_gain = lgbm_plot_trees_and_importance(lgbm_A, featA, \"LightGBM A (80/20)\")\n",
    "impB_gain = lgbm_plot_trees_and_importance(lgbm_B, featB, \"LightGBM B (90/10)\")"
   ],
   "id": "ecf085c1de53c11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lgbm_cv_scores(X, y, k, params):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    rows = []\n",
    "    for fold, (tr, va) in enumerate(skf.split(X, y), 1):\n",
    "        clf = lgb.LGBMClassifier(**params)\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        yp = clf.predict(X[va])\n",
    "        rows.append({\n",
    "            \"fold\": fold,\n",
    "            \"acc\":  accuracy_score(y[va], yp),\n",
    "            \"prec\": precision_score(y[va], yp, average=\"macro\"),\n",
    "            \"rec\":  recall_score(y[va], yp, average=\"macro\"),\n",
    "            \"f1\":   f1_score(y[va], yp, average=\"macro\"),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df, df.mean(numeric_only=True).to_dict()\n",
    "\n",
    "print(\"CV — LightGBM A (80/20), k=5\")\n",
    "cvA_df, cvA_mean = lgbm_cv_scores(XA_tr, yA_tr, k=5, params=LGBM_BASE)\n",
    "display(cvA_df); print(\"Mean:\", {k: round(v,3) for k,v in cvA_mean.items()})\n",
    "\n",
    "print(\"\\nCV — LightGBM B (90/10), k=10\")\n",
    "cvB_df, cvB_mean = lgbm_cv_scores(XB_tr, yB_tr, k=10, params=LGBM_BASE)\n",
    "display(cvB_df); print(\"Mean:\", {k: round(v,3) for k,v in cvB_mean.items()})\n"
   ],
   "id": "f667defaf663b19c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reuse your earlier helpers: clean_ames, make_price_classes, fit_transform_splits, train_band_filter\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = \"AmesHousing.csv\"  # tab-separated\n",
    "\n",
    "def run_strategy_lgbm(tag, test_size, use_rare_bucket=False, winsorize=False, band_filter=False):\n",
    "    df_tr, df_te, meta = clean_ames(\n",
    "        DATA_PATH, test_size=test_size, random_state=RANDOM_STATE,\n",
    "        return_meta=True, use_rare_bucket=use_rare_bucket, winsorize=winsorize,\n",
    "        drop_exact_duplicates=True, drop_audit_flags=True\n",
    "    )\n",
    "    tr_cls, te_cls, _ = make_price_classes(df_tr, df_te, n_bins=5)\n",
    "\n",
    "    def split_xy(df):\n",
    "        X = df.drop(columns=[\"SalePrice\",\"PriceClass\",\"PriceClassInterval\"], errors=\"ignore\")\n",
    "        y = df[\"PriceClass\"].astype(\"int64\")\n",
    "        return X, y\n",
    "\n",
    "    Xtr, ytr = split_xy(tr_cls); Xte, yte = split_xy(te_cls)\n",
    "    Xtr_m, Xte_m, feats, pre = fit_transform_splits(Xtr, Xte)\n",
    "\n",
    "    # Optional: train-only band filter\n",
    "    if band_filter and {'Gr Liv Area','SalePrice'} <= set(tr_cls.columns):\n",
    "        keep = train_band_filter(tr_cls, 'Gr Liv Area', 'SalePrice', 0.10, 0.90)\n",
    "        tr_band = tr_cls.loc[keep].reset_index(drop=True)\n",
    "        Xb, yb  = split_xy(tr_band)\n",
    "        Xb_m    = pre.fit_transform(Xb)    # refit preprocessor on trimmed TRAIN\n",
    "        Xe_m    = pre.transform(Xte)\n",
    "        clf_b   = lgb.LGBMClassifier(**LGBM_BASE).fit(Xb_m, yb)\n",
    "        yp_b    = clf_b.predict(Xe_m)\n",
    "        res_b = dict(\n",
    "            band_acc=accuracy_score(yte, yp_b),\n",
    "            band_prec=precision_score(yte, yp_b, average=\"macro\"),\n",
    "            band_rec=recall_score(yte, yp_b, average=\"macro\"),\n",
    "            band_f1=f1_score(yte, yp_b, average=\"macro\"),\n",
    "            n_train_band=len(Xb)\n",
    "        )\n",
    "    else:\n",
    "        res_b = {}\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**LGBM_BASE).fit(Xtr_m, ytr)\n",
    "    yp   = clf.predict(Xte_m)\n",
    "    res = dict(\n",
    "        tag=tag,\n",
    "        acc=accuracy_score(yte, yp),\n",
    "        prec=precision_score(yte, yp, average=\"macro\"),\n",
    "        rec=recall_score(yte, yp, average=\"macro\"),\n",
    "        f1=f1_score(yte, yp, average=\"macro\"),\n",
    "        n_train=len(Xtr), n_test=len(Xte),\n",
    "        **res_b\n",
    "    )\n",
    "    return res\n",
    "\n",
    "res_lgbm = []\n",
    "# Scenario A (80/20)\n",
    "res_lgbm.append(run_strategy_lgbm(\"LGBM A: baseline\", 0.20, use_rare_bucket=False, winsorize=False, band_filter=False))\n",
    "res_lgbm.append(run_strategy_lgbm(\"LGBM A: rare_bucket\", 0.20, use_rare_bucket=True,  winsorize=False, band_filter=False))\n",
    "res_lgbm.append(run_strategy_lgbm(\"LGBM A: winsorize\",   0.20, use_rare_bucket=False, winsorize=True,  band_filter=False))\n",
    "res_lgbm.append(run_strategy_lgbm(\"LGBM A: band_filter\", 0.20, use_rare_bucket=False, winsorize=False, band_filter=True))\n",
    "\n",
    "# Scenario B (90/10)\n",
    "res_lgbm.append(run_strategy_lgbm(\"LGBM B: baseline\", 0.10, use_rare_bucket=False, winsorize=False, band_filter=False))\n",
    "res_lgbm.append(run_strategy_lgbm(\"LGBM B: rare_bucket\", 0.10, use_rare_bucket=True,  winsorize=False, band_filter=False))\n",
    "res_lgbm.append(run_strategy_lgbm(\"LGBM B: winsorize\",   0.10, use_rare_bucket=False, winsorize=True,  band_filter=False))\n",
    "res_lgbm.append(run_strategy_lgbm(\"LGBM B: band_filter\", 0.10, use_rare_bucket=False, winsorize=False, band_filter=True))\n",
    "\n",
    "comp_lgbm = pd.DataFrame(res_lgbm).sort_values(\"f1\", ascending=False)\n",
    "display(comp_lgbm)\n"
   ],
   "id": "7f04b0c11191e3f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid_lgbm = {\n",
    "    \"num_leaves\": [31, 63, 127],      # controls leaf-wise complexity\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"n_estimators\": [200, 300, 500],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "def grid_search_lgbm(Xtr, ytr, Xte, yte, grid, base=LGBM_BASE, tag=\"LGBM A\"):\n",
    "    rows = []\n",
    "    for p in ParameterGrid(grid):\n",
    "        params = base.copy(); params.update(p)\n",
    "        clf = lgb.LGBMClassifier(**params).fit(Xtr, ytr)\n",
    "        yp  = clf.predict(Xte)\n",
    "        rows.append({\n",
    "            **p,\n",
    "            \"acc\":  accuracy_score(yte, yp),\n",
    "            \"prec\": precision_score(yte, yp, average=\"macro\"),\n",
    "            \"rec\":  recall_score(yte, yp, average=\"macro\"),\n",
    "            \"f1\":   f1_score(yte, yp, average=\"macro\"),\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"f1\", ascending=False)\n",
    "    print(f\"\\n{tag} — LightGBM grid results (top)\")\n",
    "    display(df.head(10))\n",
    "    return df\n",
    "\n",
    "df_lgbm_A_grid = grid_search_lgbm(XA_tr, yA_tr, XA_te, yA_te, grid_lgbm, tag=\"LGBM A (80/20)\")\n",
    "df_lgbm_B_grid = grid_search_lgbm(XB_tr, yB_tr, XB_te, yB_te, grid_lgbm, tag=\"LGBM B (90/10)\")"
   ],
   "id": "6b8477a316438305",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# XGB baseline metrics you printed earlier:\n",
    "xgb_A = dict(acc=0.738, prec=0.742, rec=0.738, f1=0.739)\n",
    "xgb_B = dict(acc=0.733, prec=0.733, rec=0.725, f1=0.726)\n",
    "\n",
    "# From LGBM baseline above:\n",
    "lgb_A = metrics_A\n",
    "lgb_B = metrics_B\n",
    "\n",
    "cmp = pd.DataFrame([\n",
    "    {\"scenario\":\"A (80/20)\",\"model\":\"XGBoost\", **xgb_A},\n",
    "    {\"scenario\":\"A (80/20)\",\"model\":\"LightGBM\", **lgb_A},\n",
    "    {\"scenario\":\"B (90/10)\",\"model\":\"XGBoost\", **xgb_B},\n",
    "    {\"scenario\":\"B (90/10)\",\"model\":\"LightGBM\", **lgb_B},\n",
    "])\n",
    "\n",
    "# Differences (LGBM − XGB) by scenario\n",
    "diffA = {k: round(lgb_A[k]-xgb_A[k], 3) for k in [\"acc\",\"prec\",\"rec\",\"f1\"]}\n",
    "diffB = {k: round(lgb_B[k]-xgb_B[k], 3) for k in [\"acc\",\"prec\",\"rec\",\"f1\"]}\n",
    "\n",
    "display(cmp)\n",
    "print(\"\\nΔ (LGBM − XGB) — A:\", diffA)\n",
    "print(\"Δ (LGBM − XGB) — B:\", diffB)\n"
   ],
   "id": "beaade0c97b17635",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
