{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "39a20f5df2e10f08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:35.912790Z",
     "start_time": "2025-11-14T07:46:33.933485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# 0. Imports & global config\n",
    "# ============================\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, roc_curve, average_precision_score,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.options.future.infer_string = True\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = \"AmesHousing.csv\"   # fișierul original (TSV)\n",
    "ART_DIR = \"L2_artifacts\"        # aici salvăm split-urile curate\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "def simple_mode(s: pd.Series):\n",
    "    m = s.mode(dropna=True)\n",
    "    return m.iloc[0] if len(m) else np.nan\n",
    "\n",
    "# Clips negative numeric values (area/count columns) to zero.\n",
    "def enforce_nonnegative(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clip logical non-negative numerics at 0 (defensive net).\"\"\"\n",
    "    nonneg = [\n",
    "        'Lot Area','Lot Frontage','Gr Liv Area',\n",
    "        'BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF',\n",
    "        'Garage Area','Garage Cars','1st Flr SF','2nd Flr SF','Low Qual Fin SF',\n",
    "        'Wood Deck SF','Open Porch SF','Enclosed Porch','3Ssn Porch','Screen Porch',\n",
    "        'Pool Area','SalePrice'\n",
    "    ]\n",
    "    for c in nonneg:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].clip(lower=0)\n",
    "    return df\n",
    "\n",
    "def normalize_categoricals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Trim/standardize string categories (avoids hidden ‘NaN ’, ‘ y ’, etc.).\"\"\"\n",
    "    obj_cols = df.select_dtypes(include='object').columns\n",
    "    for c in obj_cols:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "        df.loc[df[c].isin(['', 'nan', 'None', 'NaT']), c] = np.nan\n",
    "    # Central Air should be Y/N\n",
    "    if 'Central Air' in df.columns:\n",
    "        df['Central Air'] = df['Central Air'].replace({'Yes': 'Y', 'No': 'N', 'y': 'Y', 'n': 'N'})\n",
    "    return df\n",
    "\n",
    "def apply_absence_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    na_none_map = {\n",
    "        'Alley': 'NoAlley',\n",
    "        'Bsmt Qual': 'NoBasement','Bsmt Cond': 'NoBasement','Bsmt Exposure': 'NoBasement',\n",
    "        'BsmtFin Type 1': 'NoBasement','BsmtFin Type 2': 'NoBasement',\n",
    "        'Fireplace Qu': 'NoFireplace',\n",
    "        'Garage Type': 'NoGarage','Garage Finish': 'NoGarage','Garage Qual': 'NoGarage','Garage Cond': 'NoGarage',\n",
    "        'Pool QC': 'NoPool','Fence': 'NoFence','Misc Feature': 'NoFeature'\n",
    "    }\n",
    "    for col, val in na_none_map.items():\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace('NA', val).fillna(val)\n",
    "    return df\n",
    "\n",
    "def fix_basement_consistency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    parts = ['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF']; total = 'Total Bsmt SF'\n",
    "    has_bsmt_area = (df[parts].fillna(0).sum(axis=1) > 0)\n",
    "    bad_expo = has_bsmt_area & (df['Bsmt Exposure'] == 'NoBasement')\n",
    "    df['Fix_BsmtExposure'] = 0\n",
    "    df.loc[bad_expo, 'Bsmt Exposure'] = 'No'\n",
    "    df.loc[bad_expo, 'Fix_BsmtExposure'] = 1\n",
    "\n",
    "    sum_parts = df[parts].fillna(0).sum(axis=1)\n",
    "    all_parts_na = df[parts].isna().all(axis=1)\n",
    "    total_na = df[total].isna()\n",
    "\n",
    "    mask_true_mismatch = (~all_parts_na) & (~total_na) & (df[total] != sum_parts)\n",
    "    mask_total_missing = (~all_parts_na) & total_na\n",
    "    df.loc[mask_true_mismatch, total] = sum_parts[mask_true_mismatch]\n",
    "    df.loc[mask_total_missing, total] = sum_parts[mask_total_missing]\n",
    "\n",
    "    mask_parts_missing = all_parts_na & (~total_na)\n",
    "    for c in parts:\n",
    "        df.loc[mask_parts_missing, c] = df.loc[mask_parts_missing, c].fillna(0)\n",
    "\n",
    "    mask_all_missing = all_parts_na & total_na & (df['Bsmt Qual'] == 'NoBasement')\n",
    "    for c in parts + [total]:\n",
    "        df.loc[mask_all_missing, c] = 0\n",
    "    return df\n",
    "\n",
    "def consolidate_garage_absence(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"If no garage (type/area/cars imply absence), zero numerics + set labels to NoGarage.\"\"\"\n",
    "    g_zero = (df.get('Garage Cars', 0).fillna(0) == 0) & (df.get('Garage Area', 0).fillna(0) == 0)\n",
    "    if 'Garage Type' in df.columns:\n",
    "        g_abs = (df['Garage Type'] == 'NoGarage') | g_zero\n",
    "        for c in ['Garage Finish','Garage Qual','Garage Cond','Garage Type']:\n",
    "            if c in df.columns:\n",
    "                df.loc[g_abs, c] = 'NoGarage'\n",
    "        for c in ['Garage Yr Blt','Garage Area','Garage Cars']:\n",
    "            if c in df.columns:\n",
    "                df.loc[g_abs, c] = 0\n",
    "    return df\n",
    "\n",
    "def apply_time_filters(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[(df['Yr Sold'] >= df['Year Built']) & (df['Yr Sold'] >= df['Year Remod/Add'])].copy()\n",
    "    df = df[df['Year Remod/Add'] >= df['Year Built']].copy()\n",
    "    mask_gyear_ok = (~df['Garage Yr Blt'].notna()) | (\n",
    "        (df['Garage Yr Blt'] >= 1880) & (df['Garage Yr Blt'] <= (df['Yr Sold'] + 1))\n",
    "    )\n",
    "    return df[mask_gyear_ok].copy()\n",
    "\n",
    "def add_binary_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['HasPool']   = (df['Pool Area'] > 0).astype(int)\n",
    "    df['HasFire']   = (df['Fireplaces'] > 0).astype(int)\n",
    "    df['HasAC']     = (df['Central Air'] == 'Y').astype(int)\n",
    "    df['HasFence']  = (df['Fence'] != 'NoFence').astype(int)\n",
    "    df['HasGarage'] = (df['Garage Cars'].fillna(0) > 0).astype(int)\n",
    "    df['AmenitiesCount'] = df[['HasPool','HasFire','HasAC','HasFence','HasGarage']].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def drop_low_signal_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    to_drop = ['Utilities','Street','Condition 2','Roof Matl','Heating','Pool QC','Misc Feature','Garage Cond']\n",
    "    keep = [c for c in to_drop if c in df.columns]\n",
    "    return df.drop(columns=keep).copy()\n",
    "\n",
    "def ordinal_encode_inplace(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ord_orders = {\n",
    "        'Exter Qual':['Po','Fa','TA','Gd','Ex'],'Exter Cond':['Po','Fa','TA','Gd','Ex'],\n",
    "        'Bsmt Qual':['NoBasement','Po','Fa','TA','Gd','Ex'],'Bsmt Cond':['NoBasement','Po','Fa','TA','Gd','Ex'],\n",
    "        'Bsmt Exposure':['NoBasement','No','Mn','Av','Gd'],\n",
    "        'BsmtFin Type 1':['NoBasement','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\n",
    "        'BsmtFin Type 2':['NoBasement','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\n",
    "        'Heating QC':['Po','Fa','TA','Gd','Ex'],'Electrical':['FuseP','FuseF','Mix','FuseA','SBrkr'],\n",
    "        'Kitchen Qual':['Po','Fa','TA','Gd','Ex'],'Fireplace Qu':['NoFireplace','Po','Fa','TA','Gd','Ex'],\n",
    "        'Garage Finish':['NoGarage','Unf','RFn','Fin'],'Garage Qual':['NoGarage','Po','Fa','TA','Gd','Ex'],\n",
    "        'Paved Drive':['N','P','Y'],'Lot Shape':['IR3','IR2','IR1','Reg'],'Land Slope':['Sev','Mod','Gtl'],\n",
    "    }\n",
    "    for col, order in ord_orders.items():\n",
    "        if col in df.columns:\n",
    "            cat = pd.Categorical(df[col], categories=order, ordered=True)\n",
    "            s = pd.Series(cat.codes, index=df.index).astype('float64')\n",
    "            s[s == -1] = np.nan\n",
    "            df[col] = s\n",
    "    return df\n",
    "\n",
    "def bucket_rare(df: pd.DataFrame, cols: list, min_count: int = 5) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            s = df[c].astype(str)  # TODO check--> edge case\n",
    "            vc = df[c].value_counts(dropna=False)\n",
    "            rare = set(vc[vc < min_count].index)\n",
    "            df[c] = df[c].where(~df[c].isin(rare), \"__Other__\")\n",
    "    return df"
   ],
   "id": "b5e16ea2c0e690e4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:35.943959Z",
     "start_time": "2025-11-14T07:46:35.925542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_train_stats(df_tr: pd.DataFrame):\n",
    "    stats = {}\n",
    "    if 'Lot Frontage' in df_tr.columns and 'Neighborhood' in df_tr.columns:\n",
    "        stats['lf_med_nb']   = df_tr.groupby('Neighborhood')['Lot Frontage'].median()\n",
    "        stats['lf_med_glob'] = df_tr['Lot Frontage'].median()\n",
    "    else:\n",
    "        stats['lf_med_nb'] = pd.Series(dtype='float64'); stats['lf_med_glob'] = np.nan\n",
    "\n",
    "    label_cols_all = ['Garage Finish','Garage Qual','Garage Cond']\n",
    "    label_cols = [c for c in label_cols_all if c in df_tr.columns]\n",
    "    g_has_tr = (\n",
    "        (df_tr.get('Garage Type', 'NoGarage') != 'NoGarage') |\n",
    "        (df_tr.get('Garage Area', pd.Series(0, index=df_tr.index)).fillna(0) > 0) |\n",
    "        (df_tr.get('Garage Cars', pd.Series(0, index=df_tr.index)).fillna(0) > 0)\n",
    "    )\n",
    "    if 'Garage Type' in df_tr.columns and any(label_cols):\n",
    "        try:\n",
    "            stats['g_modes_by_type'] = df_tr[g_has_tr].groupby('Garage Type')[label_cols].agg(simple_mode)\n",
    "        except Exception:\n",
    "            stats['g_modes_by_type'] = pd.DataFrame()\n",
    "    else:\n",
    "        stats['g_modes_by_type'] = pd.DataFrame()\n",
    "\n",
    "    stats['g_med_area_by_type'] = (df_tr[g_has_tr].groupby('Garage Type')['Garage Area'].median()\n",
    "                                   if {'Garage Type','Garage Area'} <= set(df_tr.columns) else pd.Series(dtype='float64'))\n",
    "    stats['g_med_cars_by_type'] = (df_tr[g_has_tr].groupby('Garage Type')['Garage Cars'].median()\n",
    "                                   if {'Garage Type','Garage Cars'} <= set(df_tr.columns) else pd.Series(dtype='float64'))\n",
    "\n",
    "    if {'Mas Vnr Area','Mas Vnr Type'} <= set(df_tr.columns):\n",
    "        ref = df_tr[(df_tr['Mas Vnr Area'].fillna(0) > 0) & df_tr['Mas Vnr Type'].notna() & (df_tr['Mas Vnr Type'] != 'None')]\n",
    "        stats['mvt_nb_mode'] = (ref.groupby('Neighborhood')['Mas Vnr Type'].agg(simple_mode)\n",
    "                                if 'Neighborhood' in df_tr.columns else pd.Series(dtype='object'))\n",
    "        gmode = df_tr['Mas Vnr Type'].dropna().mode()\n",
    "        stats['mvt_global_mode'] = gmode.iloc[0] if len(gmode) else 'BrkFace'\n",
    "    else:\n",
    "        stats['mvt_nb_mode'] = pd.Series(dtype='object'); stats['mvt_global_mode'] = 'BrkFace'\n",
    "\n",
    "    num_cols = [c for c in df_tr.select_dtypes(include=[np.number]).columns if c != 'SalePrice']\n",
    "    stats['num_medians'] = df_tr[num_cols].median(numeric_only=True)\n",
    "    return stats\n",
    "\n",
    "def apply_train_stats(df_block: pd.DataFrame, stats: dict) -> pd.DataFrame:\n",
    "    if {'Lot Frontage','Neighborhood'} <= set(df_block.columns) and not pd.isna(stats.get('lf_med_glob', np.nan)):\n",
    "        df_block['Lot Frontage'] = df_block['Lot Frontage'].fillna(df_block['Neighborhood'].map(stats['lf_med_nb'])).fillna(stats['lf_med_glob'])\n",
    "\n",
    "    g_has = (\n",
    "        (df_block.get('Garage Type', 'NoGarage') != 'NoGarage') |\n",
    "        (df_block.get('Garage Area', pd.Series(0, index=df_block.index)).fillna(0) > 0) |\n",
    "        (df_block.get('Garage Cars', pd.Series(0, index=df_block.index)).fillna(0) > 0)\n",
    "    )\n",
    "    if isinstance(stats.get('g_modes_by_type'), pd.DataFrame) and not stats['g_modes_by_type'].empty and 'Garage Type' in df_block.columns:\n",
    "        need_fix = g_has & (\n",
    "            (df_block.get('Garage Finish', pd.Series(np.nan, index=df_block.index)).isna()) |\n",
    "            (df_block.get('Garage Qual',   pd.Series(np.nan, index=df_block.index)).isna()) |\n",
    "            (df_block.get('Garage Cond',   pd.Series(np.nan, index=df_block.index)).isna()) |\n",
    "            (df_block.get('Garage Finish', pd.Series('NoGarage', index=df_block.index)) == 'NoGarage') |\n",
    "            (df_block.get('Garage Qual',   pd.Series('NoGarage', index=df_block.index)) == 'NoGarage') |\n",
    "            (df_block.get('Garage Cond',   pd.Series('NoGarage', index=df_block.index)) == 'NoGarage')\n",
    "        )\n",
    "        for c in ['Garage Finish','Garage Qual','Garage Cond']:\n",
    "            if c in df_block.columns and c in stats['g_modes_by_type'].columns:\n",
    "                fill_vals = df_block.loc[need_fix, 'Garage Type'].map(stats['g_modes_by_type'][c])\n",
    "                df_block.loc[need_fix, c] = df_block.loc[need_fix, c].fillna(fill_vals)\n",
    "\n",
    "    if {'Garage Area','Garage Type'} <= set(df_block.columns) and not stats.get('g_med_area_by_type', pd.Series()).empty:\n",
    "        m_area_na = g_has & df_block['Garage Area'].isna()\n",
    "        df_block.loc[m_area_na, 'Garage Area'] = df_block.loc[m_area_na, 'Garage Type'].map(stats['g_med_area_by_type'])\n",
    "    if {'Garage Cars','Garage Type'} <= set(df_block.columns) and not stats.get('g_med_cars_by_type', pd.Series()).empty:\n",
    "        m_cars_na = g_has & df_block['Garage Cars'].isna()\n",
    "        df_block.loc[m_cars_na, 'Garage Cars'] = df_block.loc[m_cars_na, 'Garage Type'].map(stats['g_med_cars_by_type'])\n",
    "\n",
    "    if {'Mas Vnr Area','Mas Vnr Type'} <= set(df_block.columns):\n",
    "        area = df_block['Mas Vnr Area']; typ = df_block['Mas Vnr Type']\n",
    "        m_area0 = area.fillna(0) == 0; m_area_pos = area.fillna(0) > 0\n",
    "        m_type_none = typ == 'None'; m_type_na = typ.isna()\n",
    "        df_block.loc[m_type_na & m_area0, 'Mas Vnr Type'] = 'None'\n",
    "        df_block.loc[(~m_type_none & ~m_type_na) & m_area0, 'Mas Vnr Type'] = 'None'\n",
    "        mask_pos_missing = m_area_pos & (m_type_none | m_type_na)\n",
    "        nb_mode = stats.get('mvt_nb_mode', pd.Series(dtype='object')); global_mode = stats.get('mvt_global_mode', 'BrkFace')\n",
    "        if not nb_mode.empty and 'Neighborhood' in df_block.columns:\n",
    "            nb_fill = df_block.loc[mask_pos_missing, 'Neighborhood'].map(nb_mode).fillna(global_mode)\n",
    "        else:\n",
    "            nb_fill = pd.Series(global_mode, index=df_block.index).loc[mask_pos_missing]\n",
    "        df_block.loc[mask_pos_missing, 'Mas Vnr Type'] = nb_fill\n",
    "    return df_block\n",
    "\n",
    "def fill_not_present_numerics(df_block: pd.DataFrame) -> pd.DataFrame:\n",
    "    exist_num = ['Garage Yr Blt','Garage Area','Garage Cars',\n",
    "                 'BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF',\n",
    "                 'Bsmt Full Bath','Bsmt Half Bath','Pool Area','Mas Vnr Area']\n",
    "    for c in exist_num:\n",
    "        if c in df_block.columns:\n",
    "            df_block[f'{c}_was_missing'] = df_block[c].isna().astype(int)\n",
    "            df_block[c] = df_block[c].fillna(0)\n",
    "    return df_block\n",
    "\n",
    "def fill_remaining_numerics_with_train_median(df_block: pd.DataFrame, num_medians: pd.Series) -> pd.DataFrame:\n",
    "    for c in df_block.select_dtypes(include=[np.number]).columns:\n",
    "        if df_block[c].isna().any():\n",
    "            df_block[c] = df_block[c].fillna(num_medians.get(c, df_block[c].median()))\n",
    "    return df_block"
   ],
   "id": "8ee39297e4a56785",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:35.965962Z",
     "start_time": "2025-11-14T07:46:35.955502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_sanity_report(df_raw, df_train_clean, df_test_clean, meta, make_plots=True):\n",
    "    df_clean_all = pd.concat([df_train_clean, df_test_clean], ignore_index=True)\n",
    "    n_raw = meta.get('n_raw', len(df_raw)); n_after_time = meta.get('n_after_time', len(df_clean_all))\n",
    "    dropped_time = n_raw - n_after_time; pct_dropped = (dropped_time / n_raw) * 100 if n_raw else 0\n",
    "    print(\"=== Sanity report ===\")\n",
    "    print(f\"- Rows initiale: {n_raw}\")\n",
    "    print(f\"- După filtre temporale: {n_after_time}  (drop: {dropped_time} | {pct_dropped:.2f}%)\")\n",
    "    n_fix_bsmt = meta.get('n_fix_bsmt_exposure', int(df_clean_all.get('Fix_BsmtExposure', pd.Series(0)).sum()))\n",
    "    print(f\"- Corecții Bsmt Exposure (NoBasement -> No când există arii): {n_fix_bsmt}\")\n",
    "\n",
    "    parts = ['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF']; total = 'Total Bsmt SF'\n",
    "    if all(c in df_clean_all.columns for c in parts+[total]):\n",
    "        mismatch = (df_clean_all[total] != df_clean_all[parts].fillna(0).sum(axis=1)).sum()\n",
    "        print(f\"- Identități subsol (Total == sum(parts)) → mismatches: {mismatch}\")\n",
    "    else:\n",
    "        print(\"- Identități subsol: coloane lipsă, skip.\")\n",
    "\n",
    "    na_raw = df_raw.isna().sum().sort_values(ascending=False)\n",
    "    na_clean = df_clean_all.isna().sum().sort_values(ascending=False)\n",
    "    print(\"\\nTop 10 coloane cu NaN (înainte):\"); print(na_raw.head(10))\n",
    "    print(\"\\nTop 10 coloane cu NaN (după curățare):\"); print(na_clean.head(10))\n",
    "    print(f\"\\nShapes: train={df_train_clean.shape}, test={df_test_clean.shape}\")\n",
    "    if 'SalePrice' in df_raw.columns:\n",
    "        sp_raw = df_raw['SalePrice'].dropna(); sp_clean = df_clean_all['SalePrice'].dropna()\n",
    "        print(f\"SalePrice (raw):   n={sp_raw.size}, min={sp_raw.min():,.0f}, median={sp_raw.median():,.0f}, max={sp_raw.max():,.0f}\")\n",
    "        print(f\"SalePrice (clean): n={sp_clean.size}, min={sp_clean.min():,.0f}, median={sp_clean.median():,.0f}, max={sp_clean.max():,.0f}\")\n",
    "\n",
    "    if make_plots:\n",
    "        try: plot_sanity(df_raw, df_clean_all)\n",
    "        except Exception as e: print(f\"(plot warning) {e}\")\n",
    "\n",
    "def plot_sanity(df_raw, df_clean):\n",
    "    if 'SalePrice' in df_raw.columns and 'SalePrice' in df_clean.columns:\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.hist(df_raw['SalePrice'].dropna(), bins=50, alpha=0.35, label='raw')\n",
    "        plt.hist(df_clean['SalePrice'].dropna(), bins=50, alpha=0.6, label='clean')\n",
    "        plt.title(\"SalePrice: raw vs clean (hist)\"); plt.xlabel(\"SalePrice\"); plt.ylabel(\"count\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    if all(c in df_clean.columns for c in ['Gr Liv Area','SalePrice']):\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.scatter(df_clean['Gr Liv Area'], df_clean['SalePrice'], s=8, alpha=0.5)\n",
    "        plt.title(\"SalePrice vs Gr Liv Area (clean)\"); plt.xlabel(\"Gr Liv Area\"); plt.ylabel(\"SalePrice\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "def validate_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a small table of issues (row_idx, column, rule, value) without mutating df.\"\"\"\n",
    "    issues = []\n",
    "    def report(mask, col, rule):\n",
    "        idx = df.index[mask]\n",
    "        for i in idx:\n",
    "            issues.append((int(i), col, rule, df.at[i, col] if col in df.columns else None))\n",
    "\n",
    "    if {'Mo Sold','Yr Sold'} <= set(df.columns):\n",
    "        report(~df['Mo Sold'].between(1,12), 'Mo Sold', 'month_out_of_range')\n",
    "        report(~df['Yr Sold'].between(1800, 2100), 'Yr Sold', 'year_out_of_range')\n",
    "\n",
    "    if {'Overall Qual','Overall Cond'} <= set(df.columns):\n",
    "        report(~df['Overall Qual'].between(1,10), 'Overall Qual', 'qual_out_of_range')\n",
    "        report(~df['Overall Cond'].between(1,10), 'Overall Cond', 'cond_out_of_range')\n",
    "\n",
    "    if {'Year Built','Year Remod/Add'} <= set(df.columns):\n",
    "        report(df['Year Remod/Add'] < df['Year Built'], 'Year Remod/Add', 'remod_before_built')\n",
    "\n",
    "    if {'Garage Yr Blt','Yr Sold'} <= set(df.columns):\n",
    "        gy = df['Garage Yr Blt']; ys = df['Yr Sold']\n",
    "        report(gy.notna() & (gy < 1880), 'Garage Yr Blt', 'garage_too_old')\n",
    "        report(gy.notna() & (gy > ys + 1), 'Garage Yr Blt', 'garage_after_sale+1')\n",
    "\n",
    "    pos_when_present = ['Gr Liv Area','1st Flr SF','SalePrice']\n",
    "    for c in pos_when_present:\n",
    "        if c in df.columns:\n",
    "            report(df[c] < 0, c, 'negative_value')\n",
    "\n",
    "    return pd.DataFrame(issues, columns=['row_idx','column','rule','value'])"
   ],
   "id": "46fe360c8ea621f6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:35.987128Z",
     "start_time": "2025-11-14T07:46:35.978565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_ames(csv_path: str,\n",
    "               test_size: float = 0.2,\n",
    "               random_state: int = 42,\n",
    "               return_meta: bool = False,\n",
    "               use_rare_bucket: bool = False,\n",
    "               winsorize: bool = False,\n",
    "               drop_exact_duplicates: bool = True,\n",
    "               drop_audit_flags: bool = True):\n",
    "    \"\"\"\n",
    "    Deterministic, leak-free cleaning. Outlier trimming is OFF by default (see train_band_filter).\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_csv(csv_path, sep=\"\\t\")\n",
    "    meta = {'n_raw': len(df_raw), 'na_raw_top': df_raw.isna().sum().sort_values(ascending=False).head(10)}\n",
    "\n",
    "    # ---- Safe pre-split steps\n",
    "    df = df_raw.copy()\n",
    "    df = normalize_categoricals(df)\n",
    "    df = apply_absence_labels(df)\n",
    "    df = fix_basement_consistency(df)\n",
    "    df = consolidate_garage_absence(df)\n",
    "    df = enforce_nonnegative(df)\n",
    "\n",
    "    if drop_exact_duplicates:\n",
    "        before = len(df); df = df.drop_duplicates().copy(); meta['n_dropped_dupes'] = before - len(df)\n",
    "\n",
    "    n_before_time = len(df)\n",
    "    df = apply_time_filters(df)\n",
    "    meta['n_after_time'] = len(df); meta['n_dropped_time'] = n_before_time - meta['n_after_time']\n",
    "\n",
    "    df = add_binary_flags(df)\n",
    "    df = drop_low_signal_columns(df)\n",
    "\n",
    "    if use_rare_bucket:\n",
    "        nominal_candidates = ['MS SubClass','MS Zoning','Neighborhood','Condition 1','Bldg Type','House Style',\n",
    "                              'Roof Style','Exterior 1st','Exterior 2nd','Mas Vnr Type','Foundation','Lot Config',\n",
    "                              'Land Contour','Garage Type','Sale Type','Sale Condition']\n",
    "        nominal_cols = [c for c in nominal_candidates if c in df.columns]\n",
    "        df = bucket_rare(df, nominal_cols, min_count=5)\n",
    "\n",
    "    df = ordinal_encode_inplace(df)\n",
    "\n",
    "    # Drop IDs\n",
    "    df = df.drop(columns=['Order','PID'], errors='ignore')\n",
    "\n",
    "    # ---- Split early (avoid leakage)\n",
    "    train_idx, test_idx = train_test_split(df.index, test_size=test_size, random_state=random_state)\n",
    "    df_tr = df.loc[train_idx].copy(); df_te = df.loc[test_idx].copy()\n",
    "\n",
    "    # ---- Train-only stats, apply to both\n",
    "    stats = compute_train_stats(df_tr)\n",
    "    df_tr = apply_train_stats(df_tr, stats); df_te = apply_train_stats(df_te, stats)\n",
    "\n",
    "    # Not-present numerics → 0 (+indicator)\n",
    "    df_tr = fill_not_present_numerics(df_tr); df_te = fill_not_present_numerics(df_te)\n",
    "\n",
    "    # (optional) winsorization — *feature* numerics only (no target)\n",
    "    if winsorize:\n",
    "        num_cols_tr = [c for c in df_tr.select_dtypes(include=[np.number]).columns if c != 'SalePrice']\n",
    "        q_lo = df_tr[num_cols_tr].quantile(0.01); q_hi = df_tr[num_cols_tr].quantile(0.99)\n",
    "        for c in num_cols_tr:\n",
    "            df_tr[c] = df_tr[c].clip(lower=q_lo.get(c, df_tr[c].min()), upper=q_hi.get(c, df_tr[c].max()))\n",
    "            if c in df_te.columns:\n",
    "                lo = q_lo.get(c, df_tr[c].min()); hi = q_hi.get(c, df_tr[c].max())\n",
    "                df_te[c] = df_te[c].clip(lower=lo, upper=hi)\n",
    "\n",
    "    # Remaining numerics → train medians\n",
    "    df_tr = fill_remaining_numerics_with_train_median(df_tr, stats['num_medians'])\n",
    "    df_te = fill_remaining_numerics_with_train_median(df_te, stats['num_medians'])\n",
    "\n",
    "    # Reset index\n",
    "    df_tr = df_tr.reset_index(drop=True); df_te = df_te.reset_index(drop=True)\n",
    "\n",
    "    # Meta checks (report needs the flags present)\n",
    "    meta['n_fix_bsmt_exposure'] = int(df.get('Fix_BsmtExposure', pd.Series(0)).sum())\n",
    "    all_clean = pd.concat([df_tr, df_te], ignore_index=True)\n",
    "    parts = ['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF']; total = 'Total Bsmt SF'\n",
    "    meta['post_clean_bsmt_mismatch'] = (int((all_clean[total] != all_clean[parts].fillna(0).sum(axis=1)).sum())\n",
    "                                        if all(c in all_clean.columns for c in parts+[total]) else None)\n",
    "    meta['na_clean_top'] = all_clean.isna().sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "    # Validation report (non-fatal)\n",
    "    meta['validation_issues_train'] = validate_dataset(df_tr).head(15)\n",
    "    meta['validation_issues_test']  = validate_dataset(df_te).head(15)\n",
    "\n",
    "    # --- Drop audit flags after meta/report, if requested\n",
    "    if drop_audit_flags:\n",
    "        audit_cols = ['Fix_BsmtExposure', 'Fix_Garage']  # Fix_Garage may not exist\n",
    "        df_tr = df_tr.drop(columns=[c for c in audit_cols if c in df_tr.columns], errors='ignore')\n",
    "        df_te = df_te.drop(columns=[c for c in audit_cols if c in df_te.columns], errors='ignore')\n",
    "\n",
    "    if return_meta:\n",
    "        return df_tr, df_te, meta\n",
    "    return df_tr, df_te"
   ],
   "id": "3d3e9d0afeeaba0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.004762Z",
     "start_time": "2025-11-14T07:46:36.000329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "def train_band_filter(df_tr: pd.DataFrame,\n",
    "                      x_col: str = 'Gr Liv Area',\n",
    "                      y_col: str = 'SalePrice',\n",
    "                      low_q: float = 0.10,\n",
    "                      high_q: float = 0.90):\n",
    "    \"\"\"\n",
    "    Return a row mask for TRAIN keeping only points within [low_q, high_q]\n",
    "    conditional quantile band of log(y) ~ log(x). Uses sklearn QuantileRegressor.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "    x = np.log1p(df_tr[x_col].clip(lower=0)).values.reshape(-1, 1)\n",
    "    y = np.log1p(df_tr[y_col].clip(lower=0)).values\n",
    "    qr_low  = QuantileRegressor(quantile=low_q, alpha=0).fit(x, y)\n",
    "    qr_high = QuantileRegressor(quantile=high_q, alpha=0).fit(x, y)\n",
    "    y_pred_lo = qr_low.predict(x); y_pred_hi = qr_high.predict(x)\n",
    "    keep_mask = (y >= y_pred_lo) & (y <= y_pred_hi)\n",
    "    return keep_mask"
   ],
   "id": "bf5ec24a031ec3c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.025917Z",
     "start_time": "2025-11-14T07:46:36.019468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_imbalanced_columns(\n",
    "    df: pd.DataFrame,\n",
    "    max_unique: int = 10,\n",
    "    threshold: float = 0.7\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scanează toate coloanele din df și returnează un tabel cu acele coloane\n",
    "    unde o singură clasă/valoare domină (>= threshold).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "\n",
    "        if s.notna().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        vc = s.value_counts(dropna=False)\n",
    "\n",
    "        if len(vc) > max_unique:\n",
    "            continue\n",
    "\n",
    "        total = vc.sum()\n",
    "        maj_val = vc.index[0]\n",
    "        maj_cnt = int(vc.iloc[0])\n",
    "        maj_pct = maj_cnt / total\n",
    "\n",
    "        if maj_pct >= threshold:\n",
    "            rows.append({\n",
    "                \"column\": col,\n",
    "                \"dtype\": str(s.dtype),\n",
    "                \"n_unique\": len(vc),\n",
    "                \"majority_value\": maj_val,\n",
    "                \"majority_count\": maj_cnt,\n",
    "                \"majority_pct\": round(maj_pct * 100, 2),\n",
    "                \"value_counts\": vc.to_dict()\n",
    "            })\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"column\",\"dtype\",\"n_unique\",\"majority_value\",\n",
    "                                     \"majority_count\",\"majority_pct\",\"value_counts\"])\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"majority_pct\", ascending=False)"
   ],
   "id": "5edd0efcd4c2a9de",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.073743Z",
     "start_time": "2025-11-14T07:46:36.069217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Cleaning only (no outlier trimming)\n",
    "#     df_train_20, df_test_20, meta_20 = clean_ames(\n",
    "#         \"AmesHousing.csv\",\n",
    "#         test_size=0.2,\n",
    "#         random_state=42,\n",
    "#         return_meta=True,\n",
    "#         use_rare_bucket=False,   # stays OFF (safe)\n",
    "#         winsorize=False,         # stays OFF (modeling choice)\n",
    "#         drop_exact_duplicates=True,\n",
    "#         drop_audit_flags=True    # <— recommended ON for modeling\n",
    "#     )\n",
    "#     print(\"Train 20% shape:\", df_train_20.shape, \"Test 20% shape:\", df_test_20.shape)\n",
    "#\n",
    "#     # Report + quick plots\n",
    "#     generate_sanity_report(\n",
    "#         df_raw=pd.read_csv(\"AmesHousing.csv\", sep=\"\\t\"),\n",
    "#         df_train_clean=df_train_20,\n",
    "#         df_test_clean=df_test_20,\n",
    "#         meta=meta_20,\n",
    "#         make_plots=True\n",
    "#     )\n",
    "#\n",
    "#     # OPTIONAL: TRAIN-ONLY trimming (leak-free)\n",
    "#     # keep_mask = train_band_filter(df_train_20, x_col='Gr Liv Area', y_col='SalePrice', low_q=0.10, high_q=0.90)\n",
    "#     # df_train_band = df_train_20.loc[keep_mask].reset_index(drop=True)\n",
    "#     # print(f\"Band-kept rows: {keep_mask.sum()} / {len(keep_mask)} ({keep_mask.mean()*100:.1f}%)\")"
   ],
   "id": "448454ce449a0a34",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.098051Z",
     "start_time": "2025-11-14T07:46:36.095002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "RANDOM_STATE = 42"
   ],
   "id": "255832e044e5f4d9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.593169Z",
     "start_time": "2025-11-14T07:46:36.112113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 0.2 — load & clean (lock splits for A and B)\n",
    "\n",
    "DATA_PATH = \"AmesHousing.csv\"  # tab-separated\n",
    "assert os.path.exists(DATA_PATH), f\"File not found: {DATA_PATH}\"\n",
    "\n",
    "# Scenario A (80/20)\n",
    "df_train_A, df_test_A, meta_A = clean_ames(\n",
    "    DATA_PATH,\n",
    "    test_size=0.20,\n",
    "    random_state=RANDOM_STATE,\n",
    "    return_meta=True,\n",
    "    use_rare_bucket=False,\n",
    "    winsorize=False,\n",
    "    drop_exact_duplicates=True,\n",
    "    drop_audit_flags=True\n",
    ")\n",
    "\n",
    "# Scenario B (90/10)\n",
    "df_train_B, df_test_B, meta_B = clean_ames(\n",
    "    DATA_PATH,\n",
    "    test_size=0.10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    return_meta=True,\n",
    "    use_rare_bucket=False,\n",
    "    winsorize=False,\n",
    "    drop_exact_duplicates=True,\n",
    "    drop_audit_flags=True\n",
    ")\n",
    "\n",
    "print(\"A — shapes:\", df_train_A.shape, df_test_A.shape)\n",
    "print(\"B — shapes:\", df_train_B.shape, df_test_B.shape)"
   ],
   "id": "840e7d67e1467863",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A — shapes: (2213, 89) (554, 89)\n",
      "B — shapes: (2490, 89) (277, 89)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.692993Z",
     "start_time": "2025-11-14T07:46:36.607491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Unbalanced classes în df_train_A (80/20) ===\")\n",
    "imb_A = find_imbalanced_columns(df_train_A, max_unique=10, threshold=0.7)\n",
    "print(imb_A.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Unbalanced classes în df_train_B (90/10) ===\")\n",
    "imb_B = find_imbalanced_columns(df_train_B, max_unique=10, threshold=0.7)\n",
    "print(imb_B.to_string(index=False))"
   ],
   "id": "d77b015e84bf83d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Unbalanced classes în df_train_A (80/20) ===\n",
      "                    column   dtype  n_unique majority_value  majority_count  majority_pct                                                                                                      value_counts\n",
      "                 HasGarage   int64         1              1            2213        100.00                                                                                                         {1: 2213}\n",
      " Total Bsmt SF_was_missing   int64         1              0            2213        100.00                                                                                                         {0: 2213}\n",
      "   Bsmt Unf SF_was_missing   int64         1              0            2213        100.00                                                                                                         {0: 2213}\n",
      "  BsmtFin SF 2_was_missing   int64         1              0            2213        100.00                                                                                                         {0: 2213}\n",
      "  BsmtFin SF 1_was_missing   int64         1              0            2213        100.00                                                                                                         {0: 2213}\n",
      "   Garage Cars_was_missing   int64         1              0            2213        100.00                                                                                                         {0: 2213}\n",
      " Garage Yr Blt_was_missing   int64         1              0            2213        100.00                                                                                                         {0: 2213}\n",
      "   Garage Area_was_missing   int64         1              0            2213        100.00                                                                                                         {0: 2213}\n",
      "     Pool Area_was_missing   int64         1              0            2213        100.00                                                                                                         {0: 2213}\n",
      "Bsmt Half Bath_was_missing   int64         2              0            2212         99.95                                                                                                   {0: 2212, 1: 1}\n",
      "Bsmt Full Bath_was_missing   int64         2              0            2212         99.95                                                                                                   {0: 2212, 1: 1}\n",
      "                   HasPool   int64         2              0            2204         99.59                                                                                                   {0: 2204, 1: 9}\n",
      "                 Pool Area   int64        10              0            2204         99.59                                 {0: 2204, 228: 1, 648: 1, 576: 1, 800: 1, 444: 1, 368: 1, 555: 1, 738: 1, 512: 1}\n",
      "  Mas Vnr Area_was_missing   int64         2              0            2196         99.23                                                                                                  {0: 2196, 1: 17}\n",
      "             Kitchen AbvGr   int64         4              1            2132         96.34                                                                                      {1: 2132, 2: 79, 0: 1, 3: 1}\n",
      "                Land Slope float64         3            2.0            2104         95.07                                                                                     {2.0: 2104, 1.0: 95, 0.0: 14}\n",
      "               Central Air     str         2              Y            2097         94.76                                                                                             {'Y': 2097, 'N': 116}\n",
      "                     HasAC   int64         2              1            2097         94.76                                                                                                 {1: 2097, 0: 116}\n",
      "            Bsmt Half Bath float64         3            0.0            2083         94.13                                                                                     {0.0: 2083, 1.0: 128, 2.0: 2}\n",
      "               Garage Qual float64         5            3.0            2081         94.04                                                                    {3.0: 2081, 2.0: 105, 4.0: 21, 5.0: 3, 1.0: 3}\n",
      "                     Alley     str         3        NoAlley            2071         93.58                                                                         {'NoAlley': 2071, 'Grvl': 80, 'Pave': 62}\n",
      "                Functional     str         8            Typ            2061         93.13                       {'Typ': 2061, 'Min1': 54, 'Min2': 52, 'Mod': 27, 'Maj1': 12, 'Maj2': 5, 'Sev': 1, 'Sal': 1}\n",
      "               Paved Drive float64         3            2.0            2049         92.59                                                                                    {2.0: 2049, 0.0: 113, 1.0: 51}\n",
      "                Electrical float64         4            4.0            2044         92.36                                                                            {4.0: 2044, 3.0: 134, 1.0: 32, 0.0: 3}\n",
      "                 Bsmt Cond float64         6            3.0            2000         90.38                                                            {3.0: 2000, 4.0: 92, 2.0: 67, 0.0: 51, 5.0: 2, 1.0: 1}\n",
      "              Land Contour     str         4            Lvl            1988         89.83                                                                    {'Lvl': 1988, 'HLS': 93, 'Bnk': 84, 'Low': 48}\n",
      "                Exter Cond float64         5            2.0            1937         87.53                                                                    {2.0: 1937, 3.0: 231, 1.0: 37, 4.0: 7, 0.0: 1}\n",
      "               Condition 1     str         9           Norm            1926         87.03  {'Norm': 1926, 'Feedr': 123, 'Artery': 60, 'RRAn': 34, 'PosN': 29, 'RRAe': 18, 'PosA': 13, 'RRNn': 7, 'RRNe': 3}\n",
      "                 Sale Type     str        10             WD            1914         86.49 {'WD': 1914, 'New': 185, 'COD': 67, 'ConLD': 20, 'CWD': 10, 'ConLw': 6, 'ConLI': 5, 'Con': 3, 'Oth': 2, 'VWD': 1}\n",
      "            BsmtFin Type 2 float64         7            1.0            1887         85.27                                                 {1.0: 1887, 3.0: 86, 2.0: 71, 4.0: 57, 0.0: 51, 5.0: 35, 6.0: 26}\n",
      "                 Bldg Type     str         5           1Fam            1851         83.64                                            {'1Fam': 1851, 'TwnhsE': 187, 'Twnhs': 75, 'Duplex': 64, '2fmCon': 36}\n",
      "            Sale Condition     str         6         Normal            1844         83.33                        {'Normal': 1844, 'Partial': 190, 'Abnorml': 123, 'Family': 36, 'Alloca': 15, 'AdjLand': 5}\n",
      "                     Fence     str         5        NoFence            1776         80.25                                              {'NoFence': 1776, 'MnPrv': 255, 'GdPrv': 91, 'GdWo': 80, 'MnWw': 11}\n",
      "                  HasFence   int64         2              0            1776         80.25                                                                                                 {0: 1776, 1: 437}\n",
      "                 MS Zoning     str         7             RL            1748         78.99                           {'RL': 1748, 'RM': 316, 'FV': 113, 'RH': 17, 'C (all)': 15, 'A (agr)': 2, 'I (all)': 2}\n",
      "                Roof Style     str         6          Gable            1743         78.76                                   {'Gable': 1743, 'Hip': 426, 'Gambrel': 18, 'Flat': 14, 'Mansard': 7, 'Shed': 5}\n",
      "                Lot Config     str         5         Inside            1609         72.71                                              {'Inside': 1609, 'Corner': 386, 'CulDSac': 145, 'FR2': 65, 'FR3': 8}\n",
      "\n",
      "=== Unbalanced classes în df_train_B (90/10) ===\n",
      "                    column   dtype  n_unique majority_value  majority_count  majority_pct                                                                                                      value_counts\n",
      " Total Bsmt SF_was_missing   int64         1              0            2490        100.00                                                                                                         {0: 2490}\n",
      "   Bsmt Unf SF_was_missing   int64         1              0            2490        100.00                                                                                                         {0: 2490}\n",
      "  BsmtFin SF 2_was_missing   int64         1              0            2490        100.00                                                                                                         {0: 2490}\n",
      "  BsmtFin SF 1_was_missing   int64         1              0            2490        100.00                                                                                                         {0: 2490}\n",
      "     Pool Area_was_missing   int64         1              0            2490        100.00                                                                                                         {0: 2490}\n",
      "                 HasGarage   int64         1              1            2490        100.00                                                                                                         {1: 2490}\n",
      "   Garage Cars_was_missing   int64         1              0            2490        100.00                                                                                                         {0: 2490}\n",
      "   Garage Area_was_missing   int64         1              0            2490        100.00                                                                                                         {0: 2490}\n",
      "Bsmt Full Bath_was_missing   int64         2              0            2489         99.96                                                                                                   {0: 2489, 1: 1}\n",
      "Bsmt Half Bath_was_missing   int64         2              0            2489         99.96                                                                                                   {0: 2489, 1: 1}\n",
      " Garage Yr Blt_was_missing   int64         2              0            2489         99.96                                                                                                   {0: 2489, 1: 1}\n",
      "                   HasPool   int64         2              0            2477         99.48                                                                                                  {0: 2477, 1: 13}\n",
      "  Mas Vnr Area_was_missing   int64         2              0            2471         99.24                                                                                                  {0: 2471, 1: 19}\n",
      "             Kitchen AbvGr   int64         4              1            2400         96.39                                                                                      {1: 2400, 2: 88, 0: 1, 3: 1}\n",
      "                Land Slope float64         3            2.0            2372         95.26                                                                                    {2.0: 2372, 1.0: 104, 0.0: 14}\n",
      "               Central Air     str         2              Y            2366         95.02                                                                                             {'Y': 2366, 'N': 124}\n",
      "                     HasAC   int64         2              1            2366         95.02                                                                                                 {1: 2366, 0: 124}\n",
      "               Garage Qual float64         6            3.0            2344         94.14                                                            {3.0: 2344, 2.0: 115, 4.0: 23, 1.0: 4, 5.0: 3, 0.0: 1}\n",
      "            Bsmt Half Bath float64         3            0.0            2340         93.98                                                                                     {0.0: 2340, 1.0: 148, 2.0: 2}\n",
      "                     Alley     str         3        NoAlley            2332         93.65                                                                         {'NoAlley': 2332, 'Grvl': 88, 'Pave': 70}\n",
      "                Functional     str         8            Typ            2317         93.05                       {'Typ': 2317, 'Min1': 60, 'Min2': 57, 'Mod': 31, 'Maj1': 15, 'Maj2': 7, 'Sal': 2, 'Sev': 1}\n",
      "               Paved Drive float64         3            2.0            2310         92.77                                                                                    {2.0: 2310, 0.0: 124, 1.0: 56}\n",
      "                Electrical float64         5            4.0            2299         92.33                                                                    {4.0: 2299, 3.0: 152, 1.0: 35, 0.0: 3, 2.0: 1}\n",
      "                 Bsmt Cond float64         6            3.0            2246         90.20                                                           {3.0: 2246, 4.0: 105, 2.0: 75, 0.0: 60, 1.0: 2, 5.0: 2}\n",
      "              Land Contour     str         4            Lvl            2244         90.12                                                                   {'Lvl': 2244, 'HLS': 102, 'Bnk': 92, 'Low': 52}\n",
      "                Exter Cond float64         5            2.0            2183         87.67                                                                    {2.0: 2183, 3.0: 257, 1.0: 40, 4.0: 8, 0.0: 2}\n",
      "               Condition 1     str         9           Norm            2155         86.55  {'Norm': 2155, 'Feedr': 136, 'Artery': 71, 'RRAn': 44, 'PosN': 34, 'RRAe': 23, 'PosA': 15, 'RRNn': 8, 'RRNe': 4}\n",
      "                 Sale Type     str        10             WD            2150         86.35 {'WD': 2150, 'New': 211, 'COD': 75, 'ConLD': 20, 'CWD': 11, 'ConLI': 8, 'ConLw': 7, 'Con': 4, 'Oth': 3, 'VWD': 1}\n",
      "            BsmtFin Type 2 float64         7            1.0            2116         84.98                                                 {1.0: 2116, 3.0: 97, 2.0: 80, 4.0: 65, 0.0: 61, 5.0: 43, 6.0: 28}\n",
      "                 Bldg Type     str         5           1Fam            2089         83.90                                            {'1Fam': 2089, 'TwnhsE': 208, 'Twnhs': 82, 'Duplex': 73, '2fmCon': 38}\n",
      "            Sale Condition     str         6         Normal            2070         83.13                        {'Normal': 2070, 'Partial': 217, 'Abnorml': 140, 'Family': 40, 'Alloca': 18, 'AdjLand': 5}\n",
      "                     Fence     str         5        NoFence            1997         80.20                                             {'NoFence': 1997, 'MnPrv': 280, 'GdPrv': 108, 'GdWo': 93, 'MnWw': 12}\n",
      "                  HasFence   int64         2              0            1997         80.20                                                                                                 {0: 1997, 1: 493}\n",
      "                 MS Zoning     str         7             RL            1969         79.08                           {'RL': 1969, 'RM': 357, 'FV': 127, 'RH': 18, 'C (all)': 15, 'A (agr)': 2, 'I (all)': 2}\n",
      "                Roof Style     str         6          Gable            1962         78.80                                   {'Gable': 1962, 'Hip': 480, 'Gambrel': 20, 'Flat': 15, 'Mansard': 8, 'Shed': 5}\n",
      "                Lot Config     str         5         Inside            1802         72.37                                             {'Inside': 1802, 'Corner': 436, 'CulDSac': 167, 'FR2': 74, 'FR3': 11}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.722734Z",
     "start_time": "2025-11-14T07:46:36.707521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 0.3 — assertions for both scenarios\n",
    "\n",
    "def assert_no_nans(df, name):\n",
    "    nans = df.isna().sum().sum()\n",
    "    assert nans == 0, f\"{name} still has {nans} NaNs\"\n",
    "    return True\n",
    "\n",
    "def assert_same_columns(df_tr, df_te, tag):\n",
    "    c1, c2 = list(df_tr.columns), list(df_te.columns)\n",
    "    assert c1 == c2, f\"{tag}: train/test columns differ!\"\n",
    "    return True\n",
    "\n",
    "def feature_count_ok(df, approx=89):\n",
    "    n = df.shape[1]\n",
    "    print(f\"- Feature count = {n} (expected ≈ {approx})\")\n",
    "    return n\n",
    "\n",
    "print(\"Scenario A checks:\")\n",
    "assert_no_nans(df_train_A, \"train_A\"); assert_no_nans(df_test_A, \"test_A\")\n",
    "assert_same_columns(df_train_A, df_test_A, \"A\")\n",
    "nA = feature_count_ok(df_train_A)\n",
    "\n",
    "print(\"\\nScenario B checks:\")\n",
    "assert_no_nans(df_train_B, \"train_B\"); assert_no_nans(df_test_B, \"test_B\")\n",
    "assert_same_columns(df_train_B, df_test_B, \"B\")\n",
    "nB = feature_count_ok(df_train_B)\n",
    "\n",
    "# Quick expected shape sanity (non-fatal)\n",
    "print(\"\\n(Non-fatal) Expected shape hints:\")\n",
    "print(\"- A ~ (2213, 89) train / (554, 89) test\")\n",
    "print(\"- B ~ (2490, 89) train / (277, 89) test\")\n",
    "\n",
    "print(\"\\nAll Step 0.3 assertions passed!!\")\n"
   ],
   "id": "9c9e5440632d3c1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario A checks:\n",
      "- Feature count = 89 (expected ≈ 89)\n",
      "\n",
      "Scenario B checks:\n",
      "- Feature count = 89 (expected ≈ 89)\n",
      "\n",
      "(Non-fatal) Expected shape hints:\n",
      "- A ~ (2213, 89) train / (554, 89) test\n",
      "- B ~ (2490, 89) train / (277, 89) test\n",
      "\n",
      "All Step 0.3 assertions passed!!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.894883Z",
     "start_time": "2025-11-14T07:46:36.747044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 0.4 — save frozen splits and metadata\n",
    "\n",
    "OUT_DIR = \"L2_artifacts\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Data splits (CSV to avoid parquet deps)\n",
    "df_train_A.to_csv(os.path.join(OUT_DIR, \"L2_clean_train_A.csv\"), index=False)\n",
    "df_test_A .to_csv(os.path.join(OUT_DIR, \"L2_clean_test_A.csv\"),  index=False)\n",
    "df_train_B.to_csv(os.path.join(OUT_DIR, \"L2_clean_train_B.csv\"), index=False)\n",
    "df_test_B .to_csv(os.path.join(OUT_DIR, \"L2_clean_test_B.csv\"),  index=False)\n",
    "\n",
    "# Meta objects can contain Series/DataFrames; pickle them safely\n",
    "with open(os.path.join(OUT_DIR, \"meta_A.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(meta_A, f)\n",
    "with open(os.path.join(OUT_DIR, \"meta_B.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(meta_B, f)\n",
    "\n",
    "# Feature registry (exclude SalePrice for now; PriceClass will be created in Step 1)\n",
    "feature_names = [c for c in df_train_A.columns if c != \"SalePrice\"]\n",
    "with open(os.path.join(OUT_DIR, \"feature_names.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sorted(feature_names), f, indent=2)\n",
    "\n",
    "# Nice one-screen summary\n",
    "def rows_after_filters(meta):\n",
    "    return meta.get(\"n_after_time\", None)\n",
    "\n",
    "summary = {\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"scenario_A\": {\n",
    "        \"train_shape\": df_train_A.shape,\n",
    "        \"test_shape\":  df_test_A.shape,\n",
    "        \"n_features\":  df_train_A.shape[1],\n",
    "        \"rows_after_temporal_filters\": rows_after_filters(meta_A),\n",
    "    },\n",
    "    \"scenario_B\": {\n",
    "        \"train_shape\": df_train_B.shape,\n",
    "        \"test_shape\":  df_test_B.shape,\n",
    "        \"n_features\":  df_train_B.shape[1],\n",
    "        \"rows_after_temporal_filters\": rows_after_filters(meta_B),\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, \"step0_summary.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "for fn in [\n",
    "    \"L2_clean_train_A.csv\",\"L2_clean_test_A.csv\",\n",
    "    \"L2_clean_train_B.csv\",\"L2_clean_test_B.csv\",\n",
    "    \"meta_A.pkl\",\"meta_B.pkl\",\n",
    "    \"feature_names.json\",\"step0_summary.json\"\n",
    "]:\n",
    "    print(\" -\", os.path.join(OUT_DIR, fn))\n",
    "\n",
    "print(\"\\nStep 0 is complete and splits are FROZEN.\")"
   ],
   "id": "2c5bf1e34279e4a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - L2_artifacts\\L2_clean_train_A.csv\n",
      " - L2_artifacts\\L2_clean_test_A.csv\n",
      " - L2_artifacts\\L2_clean_train_B.csv\n",
      " - L2_artifacts\\L2_clean_test_B.csv\n",
      " - L2_artifacts\\meta_A.pkl\n",
      " - L2_artifacts\\meta_B.pkl\n",
      " - L2_artifacts\\feature_names.json\n",
      " - L2_artifacts\\step0_summary.json\n",
      "\n",
      "Step 0 is complete and splits are FROZEN.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:36.913337Z",
     "start_time": "2025-11-14T07:46:36.907205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 0.5 — compact summary printout\n",
    "\n",
    "def compact_meta(meta):\n",
    "    n_raw = meta.get(\"n_raw\", None)\n",
    "    n_after = meta.get(\"n_after_time\", None)\n",
    "    dropped = None if (n_raw is None or n_after is None) else (n_raw - n_after)\n",
    "    pct = None if (n_raw in (None, 0) or n_after is None) else 100.0 * dropped / n_raw\n",
    "    return f\"raw={n_raw}, after_filters={n_after}, dropped={dropped} ({pct:.2f}%)\"\n",
    "\n",
    "print(\"Scenario A:\", summary[\"scenario_A\"])\n",
    "print(\"Meta A:\", compact_meta(meta_A))\n",
    "\n",
    "print(\"\\nScenario B:\", summary[\"scenario_B\"])\n",
    "print(\"Meta B:\", compact_meta(meta_B))\n",
    "\n",
    "print(\"\\nNote: From now on, always reload from L2_artifacts/* for fair comparisons.\")"
   ],
   "id": "f3fe7a380ba0da37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario A: {'train_shape': (2213, 89), 'test_shape': (554, 89), 'n_features': 89, 'rows_after_temporal_filters': 2767}\n",
      "Meta A: raw=2930, after_filters=2767, dropped=163 (5.56%)\n",
      "\n",
      "Scenario B: {'train_shape': (2490, 89), 'test_shape': (277, 89), 'n_features': 89, 'rows_after_temporal_filters': 2767}\n",
      "Meta B: raw=2930, after_filters=2767, dropped=163 (5.56%)\n",
      "\n",
      "Note: From now on, always reload from L2_artifacts/* for fair comparisons.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:37.001917Z",
     "start_time": "2025-11-14T07:46:36.934266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1.0 — config & load frozen splits\n",
    "ART_IN  = \"L2_artifacts\"   # from Step 0\n",
    "ART_OUT = \"L3_artifacts\"   # new folder for Step 1\n",
    "os.makedirs(ART_OUT, exist_ok=True)\n",
    "\n",
    "# Load Step 0 splits (Scenario A = 80/20, Scenario B = 90/10)\n",
    "df_train_A = pd.read_csv(os.path.join(ART_IN, \"L2_clean_train_A.csv\"))\n",
    "df_test_A  = pd.read_csv(os.path.join(ART_IN, \"L2_clean_test_A.csv\"))\n",
    "df_train_B = pd.read_csv(os.path.join(ART_IN, \"L2_clean_train_B.csv\"))\n",
    "df_test_B  = pd.read_csv(os.path.join(ART_IN, \"L2_clean_test_B.csv\"))"
   ],
   "id": "64f3b83113c9a87d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:37.019777Z",
     "start_time": "2025-11-14T07:46:37.014738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sp = df_train_A[\"SalePrice\"]\n",
    "#\n",
    "# print(\"SalePrice min / median / max:\", sp.min(), sp.median(), sp.max())\n",
    "#\n",
    "# schemes = {\n",
    "#     \"price_3_v1_150_250\": [0, 150000, 250000, sp.max()+1],\n",
    "#     \"price_3_v2_140_220\": [0, 140000, 220000, sp.max()+1],\n",
    "#     \"price_3_v3_160_260\": [0, 160000, 260000, sp.max()+1],\n",
    "#     \"price_4_v1_140_200_300\": [0, 140000, 200000, 300000, sp.max()+1],\n",
    "#     \"price_4_v2_150_220_300\": [0, 150000, 220000, 300000, sp.max()+1],\n",
    "# }\n",
    "#\n",
    "# def summarize_scheme(name, bins):\n",
    "#     tmp = df_train_A.copy()\n",
    "#     tmp[name] = pd.cut(sp, bins=bins, include_lowest=True, labels=False)\n",
    "#\n",
    "#     vc = tmp[name].value_counts().sort_index()\n",
    "#     pct = tmp[name].value_counts(normalize=True).sort_index() * 100\n",
    "#\n",
    "#     print(f\"\\n=== Schema: {name} ===\")\n",
    "#     print(\"Bin edges:\", [int(b) for b in bins])\n",
    "#     print(\"\\nCounts & %:\")\n",
    "#     print(pd.DataFrame({\n",
    "#         \"count\": vc,\n",
    "#         \"pct\": pct.round(2)\n",
    "#     }))\n",
    "#\n",
    "#     print(\"\\nPrice range per class (TRAIN_A):\")\n",
    "#     grp = tmp.groupby(name)[\"SalePrice\"].agg([\"count\",\"median\",\"min\",\"max\"]).astype(int)\n",
    "#     print(grp)\n",
    "#\n",
    "# for name, bins in schemes.items():\n",
    "#     summarize_scheme(name, bins)"
   ],
   "id": "4881f0a286f83e2f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T07:46:37.038094Z",
     "start_time": "2025-11-14T07:46:37.035722Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "db6859cc9da82e51",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
